[{"title": "Understanding Keras LSTMs", "question_body": "<p>I am trying to reconcile my understand of LSTMs and pointed out here in <a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\" rel=\"noreferrer\">this post by Christopher Olah</a> implemented in Keras. I am following the <a href=\"http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\" rel=\"noreferrer\">blog written by Jason Brownlee</a> for the Keras tutorial. What I am mainly confused about is, </p>\n\n<ol>\n<li>The reshaping of the data series into <code>[samples, time steps, features]</code> and,</li>\n<li>The stateful LSTMs </li>\n</ol>\n\n<p>Lets concentrate on the above two questions with reference to the code pasted below:</p>\n\n<pre><code># reshape into X=t and Y=t+1\nlook_back = 3\ntrainX, trainY = create_dataset(train, look_back)\ntestX, testY = create_dataset(test, look_back)\n\n# reshape input to be [samples, time steps, features]\ntrainX = numpy.reshape(trainX, (trainX.shape[0], look_back, 1))\ntestX = numpy.reshape(testX, (testX.shape[0], look_back, 1))\n########################\n# The IMPORTANT BIT\n##########################\n# create and fit the LSTM network\nbatch_size = 1\nmodel = Sequential()\nmodel.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nfor i in range(100):\n    model.fit(trainX, trainY, nb_epoch=1, batch_size=batch_size, verbose=2, shuffle=False)\n    model.reset_states()\n</code></pre>\n\n<p>Note: create_dataset takes a sequence of length N and returns a <code>N-look_back</code> array of which each element is a <code>look_back</code> length sequence.    </p>\n\n<h1>What is Time Steps and Features?</h1>\n\n<p>As can be seen TrainX is a 3-D array with Time_steps and Feature being the last two dimensions respectively (3 and 1 in this particular code). With respect to the image below, does this mean that we are considering the <code>many to one</code> case, where the number of pink boxes are 3? Or does it literally mean the chain length is 3 (i.e. only 3 green boxes considered). <a href=\"https://i.stack.imgur.com/kwhAP.jpg\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/kwhAP.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>Does the features argument become relevant when we consider multivariate series? e.g. modelling two financial stocks simultaneously? </p>\n\n<h1>Stateful LSTMs</h1>\n\n<p>Does stateful LSTMs mean that we save the cell memory values between runs of batches? If this is the case, <code>batch_size</code> is one, and the memory is reset between the training runs so what was the point of saying that it was stateful. I'm guessing this is related to the fact that training data is not shuffled, but I'm not sure how.</p>\n\n<p>Any thoughts?\nImage reference: <a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\" rel=\"noreferrer\">http://karpathy.github.io/2015/05/21/rnn-effectiveness/</a></p>\n\n<h2>Edit 1:</h2>\n\n<p>A bit confused about @van's comment about the red and green boxes being equal. So just to confirm, does the following API calls correspond to the unrolled diagrams? Especially noting the second diagram (<code>batch_size</code> was arbitrarily chosen.):\n<a href=\"https://i.stack.imgur.com/sW207.jpg\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/sW207.jpg\" alt=\"enter image description here\"></a>\n<a href=\"https://i.stack.imgur.com/15V2C.jpg\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/15V2C.jpg\" alt=\"enter image description here\"></a></p>\n\n<h2>Edit 2:</h2>\n\n<p>For people who have done Udacity's deep learning course and still confused about the time_step argument, look at the following discussion: <a href=\"https://discussions.udacity.com/t/rnn-lstm-use-implementation/163169\" rel=\"noreferrer\">https://discussions.udacity.com/t/rnn-lstm-use-implementation/163169</a></p>\n\n<h2>Update:</h2>\n\n<p>It turns out <code>model.add(TimeDistributed(Dense(vocab_len)))</code> was what I was looking for. Here is an example: <a href=\"https://github.com/sachinruk/ShakespeareBot\" rel=\"noreferrer\">https://github.com/sachinruk/ShakespeareBot</a></p>\n\n<h2>Update2:</h2>\n\n<p>I have summarised most of my understanding of LSTMs here: <a href=\"https://www.youtube.com/watch?v=ywinX5wgdEU\" rel=\"noreferrer\">https://www.youtube.com/watch?v=ywinX5wgdEU</a></p>\n", "link": "https://stackoverflow.com/questions/38714959/understanding-keras-lstms", "question_id": 38714959, "accepted_answer_id": 38737941, "answer_body": "<p>First of all, you choose great tutorials(<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">1</a>,<a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\">2</a>) to start.</p>\n\n<p><strong>What Time-step means</strong>: <code>Time-steps==3</code> in X.shape (Describing data shape) means there are three pink boxes. Since in Keras each step requires an input, therefore the number of the green boxes should usually equal to the number of red boxes. Unless you hack the structure.</p>\n\n<p><strong>many to many vs. many to one</strong>: In keras, there is a <code>return_sequences</code> parameter when your initializing <code>LSTM</code> or <code>GRU</code> or <code>SimpleRNN</code>. When <code>return_sequences</code> is <code>False</code> (by default), then it is <strong>many to one</strong> as shown in the picture. Its return shape is <code>(batch_size, hidden_unit_length)</code>, which represent the last state. When <code>return_sequences</code> is <code>True</code>, then it is <strong>many to many</strong>. Its return shape is <code>(batch_size, time_step, hidden_unit_length)</code></p>\n\n<p><strong>Does the features argument become relevant</strong>: Feature argument means <strong>\"How big is your red box\"</strong> or what is the input dimension each step. If you want to predict from, say, 8 kinds of market information, then you can generate your data with <code>feature==8</code>.</p>\n\n<p><strong>Stateful</strong>: You can look up <a href=\"https://github.com/fchollet/keras/blob/master/keras/layers/recurrent.py#L223\">the source code</a>. When initializing the state, if <code>stateful==True</code>, then the state from last training will be used as the initial state, otherwise it will generate a new state. I haven't turn on <code>stateful</code> yet. However, I disagree with that the <code>batch_size</code> can only be 1 when <code>stateful==True</code>. </p>\n\n<p>Currently, you generate your data with collected data. Image your stock information is coming as stream, rather than waiting for a day to collect all sequential, you would like to generate input data <strong>online</strong> while training/predicting with network. If you have 400 stocks sharing a same network, then you can set <code>batch_size==400</code>. </p>\n"}, {"title": "Keras input explanation: input_shape, units, batch_size, dim, etc", "question_body": "<p>For any Keras layer (<code>Layer</code> class), can someone explain how to understand the difference between <code>input_shape</code>, <code>units</code>, <code>dim</code>, etc.?  </p>\n\n<p>For example the doc says <code>units</code> specify the output shape of a layer. </p>\n\n<p>In the image of the neural net below <code>hidden layer1</code> has 4 units. Does this directly translate to the <code>units</code> attribute of the <code>Layer</code> object? Or does <code>units</code> in Keras equal the shape of every weight in the hidden layer times the number of units? </p>\n\n<p>In short how does one understand/visualize the attributes of the model -  in particular the layers - with the image below? \n<a href=\"https://i.stack.imgur.com/iHW2o.jpg\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/iHW2o.jpg\" alt=\"enter image description here\"></a></p>\n", "link": "https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc", "question_id": 44747343, "accepted_answer_id": 44748370, "answer_body": "<h2>Units:</h2>\n\n<blockquote>\n  <p>The amount of \"neurons\", or \"cells\", or whatever the layer has inside it.   </p>\n</blockquote>\n\n<p>It's a property of each layer, and yes, it's related to the output shape (as we will see later). In your picture, except for the input layer, which is conceptually different from other layers, you have: </p>\n\n<ul>\n<li>Hidden layer 1: 4 units (4 neurons)   </li>\n<li>Hidden layer 2: 4 units     </li>\n<li>Last layer: 1 unit</li>\n</ul>\n\n<h2>Shapes</h2>\n\n<p>Shapes are consequences of the model's configuration. Shapes are tuples representing how many elements an array or tensor has in each dimension. </p>\n\n<p><strong>Ex:</strong> a shape <code>(30,4,10)</code> means an array or tensor with 3 dimensions, containing 30 elements in the first dimension, 4 in the second and 10 in the third, totaling 30*4*10 = 1200 elements or numbers.   </p>\n\n<h2>The input shape</h2>\n\n<p>What flows between layers are tensors. Tensors can be seen as matrices, with shapes.   </p>\n\n<p>In Keras, the input layer itself is not a layer, but a tensor. It's the starting tensor you send to the first hidden layer. This tensor must have the same shape as your training data. </p>\n\n<p><strong>Example:</strong> if you have 30 images of 50x50 pixels in RGB (3 channels), the shape of your input data is <code>(30,50,50,3)</code>. Then your input layer tensor, must have this shape (see details in the \"shapes in keras\" section).   </p>\n\n<p>Each type of layer requires the input with a certain number of dimensions:</p>\n\n<ul>\n<li><code>Dense</code> layers require inputs as <code>(batch_size, input_size)</code>    \n\n<ul>\n<li>or <code>(batch_size, optional,...,optional, input_size)</code>   </li>\n</ul></li>\n<li>2D convolutional layers need inputs as:\n\n<ul>\n<li>if using <code>channels_last</code>: <code>(batch_size, imageside1, imageside2, channels)</code>    </li>\n<li>if using <code>channels_first</code>: <code>(batch_size, channels, imageside1, imageside2)</code>   </li>\n</ul></li>\n<li>1D convolutions and recurrent layers use <code>(batch_size, sequence_length, features)</code>   \n\n<ul>\n<li><a href=\"https://stackoverflow.com/a/50235563/2097240\">Details on how to prepare data for recurrent layers</a></li>\n</ul></li>\n</ul>\n\n<p>Now, the input shape is the only one you must define, because your model cannot know it. Only you know that, based on your training data.   </p>\n\n<p>All the other shapes are calculated automatically based on the units and particularities of each layer.  </p>\n\n<h2>Relation between shapes and units - The output shape</h2>\n\n<p>Given the input shape, all other shapes are results of layers calculations.   </p>\n\n<p>The \"units\" of each layer will define the output shape (the shape of the tensor that is produced by the layer and that will be the input of the next layer).  </p>\n\n<p>Each type of layer works in a particular way. Dense layers have output shape based on \"units\", convolutional layers have output shape based on \"filters\". But it's always based on some layer property. (See the documentation for what each layer outputs)   </p>\n\n<p>Let's show what happens with \"Dense\" layers, which is the type shown in your graph.   </p>\n\n<p>A dense layer has an output shape of <code>(batch_size,units)</code>. So, yes, units, the property of the layer, also defines the output shape.    </p>\n\n<ul>\n<li>Hidden layer 1: 4 units, output shape: <code>(batch_size,4)</code>.   </li>\n<li>Hidden layer 2: 4 units, output shape: <code>(batch_size,4)</code>.     </li>\n<li>Last layer: 1 unit, output shape: <code>(batch_size,1)</code>.      </li>\n</ul>\n\n<h2>Weights</h2>\n\n<p>Weights will be entirely automatically calculated based on the input and the output shapes. Again, each type of layer works in a certain way. But the weights will be a matrix capable of transforming the input shape into the output shape by some mathematical operation. </p>\n\n<p>In a dense layer, weights multiply all inputs. It's a matrix with one column per input and one row per unit, but this is often not important for basic works. </p>\n\n<p>In the image, if each arrow had a multiplication number on it, all numbers together would form the weight matrix.</p>\n\n<h2>Shapes in Keras</h2>\n\n<p>Earlier, I gave an example of 30 images, 50x50 pixels and 3 channels, having an input shape of <code>(30,50,50,3)</code>.   </p>\n\n<p>Since the input shape is the only one you need to define, Keras will demand it in the first layer. </p>\n\n<p>But in this definition, Keras ignores the first dimension, which is the batch size. Your model should be able to deal with any batch size, so you define only the other dimensions:</p>\n\n<pre><code>input_shape = (50,50,3)\n    #regardless of how many images I have, each image has this shape        \n</code></pre>\n\n<p>Optionally, or when it's required by certain kinds of models, you can pass the shape containing the batch size via <code>batch_input_shape=(30,50,50,3)</code> or <code>batch_shape=(30,50,50,3)</code>. This limits your training possibilities to this unique batch size, so it should be used only when really required.</p>\n\n<p>Either way you choose, tensors in the model will have the batch dimension.</p>\n\n<p>So, even if you used <code>input_shape=(50,50,3)</code>, when keras sends you messages, or when you print the model summary, it will show <code>(None,50,50,3)</code>.</p>\n\n<p>The first dimension is the batch size, it's <code>None</code> because it can vary depending on how many examples you give for training. (If you defined the batch size explicitly, then the number you defined will appear instead of <code>None</code>)</p>\n\n<p>Also, in advanced works, when you actually operate directly on the tensors (inside Lambda layers or in the loss function, for instance), the batch size dimension will be there.   </p>\n\n<ul>\n<li>So, when defining the input shape, you ignore the batch size: <code>input_shape=(50,50,3)</code>   </li>\n<li>When doing operations directly on tensors, the shape will be again <code>(30,50,50,3)</code>    </li>\n<li>When keras sends you a message, the shape will be <code>(None,50,50,3)</code> or <code>(30,50,50,3)</code>, depending on what type of message it sends you.   </li>\n</ul>\n\n<h1>Dim</h1>\n\n<p>And in the end, what is <code>dim</code>?   </p>\n\n<p>If your input shape has only one dimension, you don't need to give it as a tuple, you give <code>input_dim</code> as a scalar number. </p>\n\n<p>So, in your model, where your input layer has 3 elements, you can use any of these two:   </p>\n\n<ul>\n<li><code>input_shape=(3,)</code> -- The comma is necessary when you have only one dimension    </li>\n<li><code>input_dim = 3</code>    </li>\n</ul>\n\n<p>But when dealing directly with the tensors, often <code>dim</code> will refer to how many dimensions a tensor has. For instance a tensor with shape (25,10909) has 2 dimensions. </p>\n\n<hr>\n\n<h2>Defining your image in Keras</h2>\n\n<p>Keras has two ways of doing it, <code>Sequential</code> models, or the functional API <code>Model</code>. I don't like using the sequential model, later you will have to forget it anyway because you will want models with branches.  </p>\n\n<p>PS: here I ignored other aspects, such as activation functions.</p>\n\n<p><strong>With the Sequential model</strong>:</p>\n\n<pre><code>from keras.models import Sequential  \nfrom keras.layers import *  \n\nmodel = Sequential()    \n\n#start from the first hidden layer, since the input is not actually a layer   \n#but inform the shape of the input, with 3 elements.    \nmodel.add(Dense(units=4,input_shape=(3,))) #hidden layer 1 with input\n\n#further layers:    \nmodel.add(Dense(units=4)) #hidden layer 2\nmodel.add(Dense(units=1)) #output layer   \n</code></pre>\n\n<p><strong>With the functional API Model</strong>:</p>\n\n<pre><code>from keras.models import Model   \nfrom keras.layers import * \n\n#Start defining the input tensor:\ninpTensor = Input((3,))   \n\n#create the layers and pass them the input tensor to get the output tensor:    \nhidden1Out = Dense(units=4)(inpTensor)    \nhidden2Out = Dense(units=4)(hidden1Out)    \nfinalOut = Dense(units=1)(hidden2Out)   \n\n#define the model's start and end points    \nmodel = Model(inpTensor,finalOut)\n</code></pre>\n\n<p><strong>Shapes of the tensors</strong></p>\n\n<p>Remember you ignore batch sizes when defining layers: </p>\n\n<ul>\n<li>inpTensor: <code>(None,3)</code>   </li>\n<li>hidden1Out: <code>(None,4)</code>    </li>\n<li>hidden2Out: <code>(None,4)</code>  </li>\n<li>finalOut: <code>(None,1)</code>   </li>\n</ul>\n"}, {"title": "Where do I call the BatchNormalization function in Keras?", "question_body": "<p>If I want to use the BatchNormalization function in Keras, then do I need to call it once only at the beginning?</p>\n\n<p>I read this documentation for it: <a href=\"http://keras.io/layers/normalization/\">http://keras.io/layers/normalization/</a></p>\n\n<p>I don't see where I'm supposed to call it. Below is my code attempting to use it:</p>\n\n<pre><code>model = Sequential()\nkeras.layers.normalization.BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None)\nmodel.add(Dense(64, input_dim=14, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64, init='uniform'))\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, init='uniform'))\nmodel.add(Activation('softmax'))\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='binary_crossentropy', optimizer=sgd)\nmodel.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)\n</code></pre>\n\n<p>I ask because if I run the code with the second line including the batch normalization and if I run the code without the second line I get similar outputs. So either I'm not calling the function in the right place, or I guess it doesn't make that much of a difference.</p>\n", "link": "https://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras", "question_id": 34716454, "accepted_answer_id": 37979391, "answer_body": "<p>Just to answer this question in a little more detail, and as Pavel said, Batch Normalization is just another layer, so you can use it as such to create your desired network architecture. </p>\n\n<p>The general use case is to use BN between the linear and non-linear layers in your network, because it normalizes the input to your activation function, so that you're centered in the linear section of the activation function (such as Sigmoid). There's a small discussion of it <a href=\"https://www.reddit.com/r/MachineLearning/comments/2x0bq8/some_questions_regarding_batch_normalization/?su=ynbwk&amp;st=iprg6e3w&amp;sh=88bcbe40\">here</a></p>\n\n<p>In your case above, this might look like:</p>\n\n<hr>\n\n<pre><code># import BatchNormalization\nfrom keras.layers.normalization import BatchNormalization\n\n# instantiate model\nmodel = Sequential()\n\n# we can think of this chunk as the input layer\nmodel.add(Dense(64, input_dim=14, init='uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\n\n# we can think of this chunk as the hidden layer    \nmodel.add(Dense(64, init='uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('tanh'))\nmodel.add(Dropout(0.5))\n\n# we can think of this chunk as the output layer\nmodel.add(Dense(2, init='uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('softmax'))\n\n# setting up the optimization of our weights \nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='binary_crossentropy', optimizer=sgd)\n\n# running the fitting\nmodel.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2)\n</code></pre>\n\n<hr>\n\n<p>Hope this clarifies things a bit more.</p>\n"}, {"title": "How do I use the Tensorboard callback of Keras?", "question_body": "<p>I have built a neural network with Keras. I would visualize its data by Tensorboard, therefore I have utilized:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>keras.callbacks.TensorBoard(log_dir='/Graph', histogram_freq=0,\n                            write_graph=True, write_images=True)\n</code></pre>\n\n<p>as explained in <a href=\"https://keras.io/callbacks/#tensorboard\" rel=\"noreferrer\">keras.io</a>. When I run the callback I get <code>&lt;keras.callbacks.TensorBoard at 0x7f9abb3898&gt;</code>, but I don't get any file in my folder \"Graph\". Is there something wrong in how I have used this callback?</p>\n", "link": "https://stackoverflow.com/questions/42112260/how-do-i-use-the-tensorboard-callback-of-keras", "question_id": 42112260, "accepted_answer_id": 42112935, "answer_body": "<pre class=\"lang-py prettyprint-override\"><code>keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0,  \n          write_graph=True, write_images=True)\n</code></pre>\n\n<p>This line creates a Callback Tensorboard object, you should capture that object and give it to the <code>fit</code> function of your model.</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n...\nmodel.fit(...inputs and parameters..., callbacks=[tbCallBack])\n</code></pre>\n\n<p>This way you gave your callback object to the function. It will be run during the training and will output files that can be used with tensorboard.</p>\n\n<p>If you want to visualize the files created during training, run in your terminal</p>\n\n<pre><code>tensorboard --logdir path_to_current_dir/Graph \n</code></pre>\n\n<p>Hope this helps !</p>\n"}, {"title": "Keras binary_crossentropy vs categorical_crossentropy performance?", "question_body": "<p>I'm trying to train a CNN to categorize text by topic. When I use binary crossentropy I get ~80% accuracy, with categorical crossentropy I get ~50% accuracy.</p>\n\n<p>I don't understand why this is. It's a multiclass problem, doesn't that mean that I have to use categorical cross-entropy and that the results with binary cross-entropy are meaningless?</p>\n\n\n\n<pre class=\"lang-python prettyprint-override\"><code>model.add(embedding_layer)\nmodel.add(Dropout(0.25))\n# convolution layers\nmodel.add(Conv1D(nb_filter=32,\n                    filter_length=4,\n                    border_mode='valid',\n                    activation='relu'))\nmodel.add(MaxPooling1D(pool_length=2))\n# dense layers\nmodel.add(Flatten())\nmodel.add(Dense(256))\nmodel.add(Dropout(0.25))\nmodel.add(Activation('relu'))\n# output layer\nmodel.add(Dense(len(class_id_index)))\nmodel.add(Activation('softmax'))\n</code></pre>\n\n<p>Then I compile it either it like this using <code>categorical_crossentropy</code> as the loss function:</p>\n\n<pre class=\"lang-python prettyprint-override\"><code>model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n</code></pre>\n\n<p>or </p>\n\n<pre class=\"lang-python prettyprint-override\"><code>model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n</code></pre>\n", "link": "https://stackoverflow.com/questions/42081257/keras-binary-crossentropy-vs-categorical-crossentropy-performance", "question_id": 42081257, "accepted_answer_id": 46038271, "answer_body": "<p>The reason for this apparent performance discrepancy between categorical &amp; binary cross entropy is what @xtof54 has already reported in his answer, i.e.:</p>\n\n<blockquote>\n  <p>the accuracy computed with the Keras method <code>evaluate</code> is just plain\n  wrong when using binary_crossentropy with more than 2 labels</p>\n</blockquote>\n\n<p>I would like to elaborate more on this, demonstrate the actual underlying issue, explain it, and offer a remedy.</p>\n\n<p>This behavior is not a bug; the underlying reason is a rather subtle &amp; undocumented issue at how Keras actually <em>guesses</em> which accuracy to use, depending on the loss function you have selected, when you include simply <code>metrics=['accuracy']</code> in your model compilation. In other words, while your first compilation option </p>\n\n\n\n<pre class=\"lang-python prettyprint-override\"><code>model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n</code></pre>\n\n<p>is valid, your second one:</p>\n\n<pre class=\"lang-python prettyprint-override\"><code>model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n</code></pre>\n\n<p>will not produce what you expect, but the reason is not the use of binary cross entropy (which, at least in principle, is an absolutely valid loss function).</p>\n\n<p>Why is that? If you check the <a href=\"https://github.com/fchollet/keras/blob/master/keras/metrics.py\" rel=\"noreferrer\">metrics source code</a>, Keras does not define a single accuracy metric, but several different ones, among them <code>binary_accuracy</code> and <code>categorical_accuracy</code>. What happens <a href=\"https://github.com/keras-team/keras/blob/master/keras/engine/training.py#L876\" rel=\"noreferrer\">under the hood</a> is that, since you have selected binary cross entropy as your loss function and have not specified a particular accuracy metric, Keras (wrongly...) infers that you are interested in the <code>binary_accuracy</code>, and this is what it returns - while in fact you are interested in the <code>categorical_accuracy</code>.</p>\n\n<p>Let's verify that this is the case, using the <a href=\"https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py\" rel=\"noreferrer\">MNIST CNN example</a> in Keras, with the following modification:</p>\n\n<pre class=\"lang-python prettyprint-override\"><code>model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # WRONG way\n\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=2,  # only 2 epochs, for demonstration purposes\n          verbose=1,\n          validation_data=(x_test, y_test))\n\n# Keras reported accuracy:\nscore = model.evaluate(x_test, y_test, verbose=0) \nscore[1]\n# 0.9975801164627075\n\n# Actual accuracy calculated manually:\nimport numpy as np\ny_pred = model.predict(x_test)\nacc = sum([np.argmax(y_test[i])==np.argmax(y_pred[i]) for i in range(10000)])/10000\nacc\n# 0.98780000000000001\n\nscore[1]==acc\n# False    \n</code></pre>\n\n<p>To remedy this, i.e. to use indeed binary cross entropy as your loss function (as I said, nothing wrong with this, at least in principle) while still getting the <strong>categorical</strong> accuracy required by the problem at hand, you should ask explicitly for <code>categorical_accuracy</code> in the model compilation as follows:</p>\n\n<pre class=\"lang-python prettyprint-override\"><code>from keras.metrics import categorical_accuracy\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=[categorical_accuracy])\n</code></pre>\n\n<p>In the MNIST example, after training, scoring, and predicting the test set as I show above, the two metrics now are the same, as they should be:</p>\n\n<pre class=\"lang-python prettyprint-override\"><code># Keras reported accuracy:\nscore = model.evaluate(x_test, y_test, verbose=0) \nscore[1]\n# 0.98580000000000001\n\n# Actual accuracy calculated manually:\ny_pred = model.predict(x_test)\nacc = sum([np.argmax(y_test[i])==np.argmax(y_pred[i]) for i in range(10000)])/10000\nacc\n# 0.98580000000000001\n\nscore[1]==acc\n# True    \n</code></pre>\n\n<p>System setup:</p>\n\n<pre class=\"lang-python prettyprint-override\"><code>Python version 3.5.3\nTensorflow version 1.2.1\nKeras version 2.0.4\n</code></pre>\n\n<p><strong>UPDATE</strong>: After my post, I discovered that this issue had already been identified in <a href=\"https://stackoverflow.com/questions/45799474/keras-model-evaluate-vs-model-predict-accuracy-difference-in-multi-class-nlp-ta/45834857#45834857\">this answer</a>.</p>\n"}, {"title": "Keras, How to get the output of each layer?", "question_body": "<p>I have trained a binary classification model with CNN, and here is my code</p>\n\n<pre><code>model = Sequential()\nmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n                        border_mode='valid',\n                        input_shape=input_shape))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=pool_size))\n# (16, 16, 32)\nmodel.add(Convolution2D(nb_filters*2, kernel_size[0], kernel_size[1]))\nmodel.add(Activation('relu'))\nmodel.add(Convolution2D(nb_filters*2, kernel_size[0], kernel_size[1]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=pool_size))\n# (8, 8, 64) = (2048)\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2))  # define a binary classification problem\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adadelta',\n              metrics=['accuracy'])\nmodel.fit(x_train, y_train,\n          batch_size=batch_size,\n          nb_epoch=nb_epoch,\n          verbose=1,\n          validation_data=(x_test, y_test))\n</code></pre>\n\n<p>And here, I wanna get the output of each layer just like TensorFlow, how can I do that?</p>\n", "link": "https://stackoverflow.com/questions/41711190/keras-how-to-get-the-output-of-each-layer", "question_id": 41711190, "accepted_answer_id": 41712013, "answer_body": "<p>You can easily get the outputs of any layer by using: <code>model.layers[index].output</code></p>\n\n<p>For all layers use this:</p>\n\n<pre><code>from keras import backend as K\n\ninp = model.input                                           # input placeholder\noutputs = [layer.output for layer in model.layers]          # all layer outputs\nfunctors = [K.function([inp, K.learning_phase()], [out]) for out in outputs]    # evaluation functions\n\n# Testing\ntest = np.random.random(input_shape)[np.newaxis,...]\nlayer_outs = [func([test, 1.]) for func in functors]\nprint layer_outs\n</code></pre>\n\n<p>Note: To simulate Dropout use <code>learning_phase</code> as <code>1.</code> in <code>layer_outs</code> otherwise use <code>0.</code></p>\n\n<p><strong>Edit:</strong> (based on comments)</p>\n\n<p><code>K.function</code> creates theano/tensorflow tensor functions which is later used to get the output from the symbolic graph given the input. </p>\n\n<p>Now <code>K.learning_phase()</code> is required as an input as many Keras layers like Dropout/Batchnomalization depend on it to change behavior during training and test time. </p>\n\n<p>So if you remove the dropout layer in your code you can simply use:</p>\n\n<pre><code>from keras import backend as K\n\ninp = model.input                                           # input placeholder\noutputs = [layer.output for layer in model.layers]          # all layer outputs\nfunctors = [K.function([inp], [out]) for out in outputs]    # evaluation functions\n\n# Testing\ntest = np.random.random(input_shape)[np.newaxis,...]\nlayer_outs = [func([test]) for func in functors]\nprint layer_outs\n</code></pre>\n\n<p><strong>Edit 2: More optimized</strong></p>\n\n<p>I just realized that the previous answer is not that optimized as for each function evaluation the data will be transferred CPU->GPU memory and also the tensor calculations needs to be done for the lower layers over-n-over. </p>\n\n<p>Instead this is a much better way as you don't need multiple functions but a single function giving you the list of all outputs:</p>\n\n<pre><code>from keras import backend as K\n\ninp = model.input                                           # input placeholder\noutputs = [layer.output for layer in model.layers]          # all layer outputs\nfunctor = K.function([inp, K.learning_phase()], outputs )   # evaluation function\n\n# Testing\ntest = np.random.random(input_shape)[np.newaxis,...]\nlayer_outs = functor([test, 1.])\nprint layer_outs\n</code></pre>\n"}, {"title": "What is an Embedding in Keras?", "question_body": "<p>Keras documentation isn't clear what this actually is. I understand we can use this to compress the input feature space into a smaller one. But how is this done from a neural design perspective? Is it an autoenocder, RBM?</p>\n", "link": "https://stackoverflow.com/questions/38189713/what-is-an-embedding-in-keras", "question_id": 38189713, "accepted_answer_id": null}, {"title": "Can Keras with Tensorflow backend be forced to use CPU or GPU at will?", "question_body": "<p>I have Keras installed with the Tensorflow backend and CUDA.  I'd like to sometimes on demand force Keras to use CPU.  Can this be done without say installing a separate CPU-only Tensorflow in a virtual environment?  If so how?  If the backend were Theano, the flags could be set, but I have not heard of Tensorflow flags accessible via Keras.  </p>\n", "link": "https://stackoverflow.com/questions/40690598/can-keras-with-tensorflow-backend-be-forced-to-use-cpu-or-gpu-at-will", "question_id": 40690598, "accepted_answer_id": 42750563, "answer_body": "<p>If you want to force Keras to use CPU</p>\n\n<h2>Way 1</h2>\n\n<pre><code>import os\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n</code></pre>\n\n<p>before Keras / Tensorflow is imported.</p>\n\n<h2>Way 2</h2>\n\n<p>Run your script as</p>\n\n<pre><code>$ CUDA_VISIBLE_DEVICES=\"\" ./your_keras_code.py\n</code></pre>\n\n<p>See also </p>\n\n<ol>\n<li><a href=\"https://github.com/keras-team/keras/issues/152\" rel=\"noreferrer\">https://github.com/keras-team/keras/issues/152</a></li>\n<li><a href=\"https://github.com/fchollet/keras/issues/4613\" rel=\"noreferrer\">https://github.com/fchollet/keras/issues/4613</a></li>\n</ol>\n"}, {"title": "Many to one and many to many LSTM examples in Keras", "question_body": "<p>I try to understand LSTMs and how to build them with Keras. I found out, that there are principally the 4 modes to run a RNN (the 4 right ones in the picture)</p>\n\n<p><a href=\"https://i.stack.imgur.com/b4sus.jpg\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/b4sus.jpg\" alt=\"enter image description here\"></a>\nImage source: <a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\" rel=\"noreferrer\">Andrej Karpathy</a></p>\n\n<p>Now I wonder how a minimalistic code snippet for each of them would look like in Keras.\nSo something like</p>\n\n<pre><code>model = Sequential()\nmodel.add(LSTM(128, input_shape=(timesteps, data_dim)))\nmodel.add(Dense(1))\n</code></pre>\n\n<p>for each of the 4 tasks, maybe with a little bit of explanation.</p>\n", "link": "https://stackoverflow.com/questions/43034960/many-to-one-and-many-to-many-lstm-examples-in-keras", "question_id": 43034960, "accepted_answer_id": 43047615, "answer_body": "<p>So:</p>\n\n<ol>\n<li><strong>One-to-one</strong>: you could use a <code>Dense</code> layer as you are not processing sequences:</li>\n</ol>\n\n<pre class=\"lang-py prettyprint-override\"><code>    model.add(Dense(output_size, input_shape=input_shape))\n</code></pre>\n\n<p>2. <strong>One-to-many</strong>: this option is not supported well as chaining models is not very easy in <code>Keras</code>, so the following version is the easiest one:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    model.add(RepeatVector(number_of_times, input_shape=input_shape))\n    model.add(LSTM(output_size, return_sequences=True))\n</code></pre>\n\n<ol start=\"3\">\n<li><strong>Many-to-one</strong>: actually, your code snippet is (almost) an example of this approach:</li>\n</ol>\n\n<pre class=\"lang-py prettyprint-override\"><code>    model = Sequential()\n    model.add(LSTM(1, input_shape=(timesteps, data_dim)))\n</code></pre>\n\n<ol start=\"4\">\n<li><strong>Many-to-many</strong>: This is the easiest snippet when the length of the input and output matches the number of recurrent steps:</li>\n</ol>\n\n<pre class=\"lang-py prettyprint-override\"><code>    model = Sequential()\n    model.add(LSTM(1, input_shape=(timesteps, data_dim), return_sequences=True))\n</code></pre>\n\n<ol start=\"5\">\n<li><strong>Many-to-many when number of steps differ from input/output length</strong>: this is freaky hard in Keras. There are no easy code snippets to code that.</li>\n</ol>\n\n<p><strong>EDIT: Ad 5</strong></p>\n\n<p>In one of my recent applications, we implemented something which might be similar to <em>many-to-many</em> from the 4th image. In case you want to have a network with the following architecture (when an input is longer than the output):</p>\n\n<pre><code>                                        O O O\n                                        | | |\n                                  O O O O O O\n                                  | | | | | | \n                                  O O O O O O\n</code></pre>\n\n<p>You could achieve this in the following manner:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    model = Sequential()\n    model.add(LSTM(1, input_shape=(timesteps, data_dim), return_sequences=True))\n    model.add(Lambda(lambda x: x[:, -N:, :]\n</code></pre>\n\n<p>Where <code>N</code> is the number of last steps you want to cover (on image <code>N = 3</code>).</p>\n\n<p>From this point getting to:</p>\n\n<pre><code>                                        O O O\n                                        | | |\n                                  O O O O O O\n                                  | | | \n                                  O O O \n</code></pre>\n\n<p>is as simple as artificial padding sequence of length <code>N</code> using e.g. with <code>0</code> vectors, in order to adjust it to an appropriate size. </p>\n"}, {"title": "Can I run Keras model on gpu?", "question_body": "<p>I'm running a Keras model, with a submission deadline of 36 hours, if I train my model on the cpu it will take approx 50 hours, is there a way to run Keras on gpu?</p>\n\n<p>I'm using Tensorflow backend and running it on my Jupyter notebook, without anaconda installed.</p>\n", "link": "https://stackoverflow.com/questions/45662253/can-i-run-keras-model-on-gpu", "question_id": 45662253, "accepted_answer_id": 45662992, "answer_body": "<p>Yes you can run keras models on GPU. Few things you will have to check first.</p>\n\n<ol>\n<li>your system has GPU (Nvidia. As AMD doesn't work yet)</li>\n<li>You have installed the GPU version of tensorflow </li>\n<li>You have installed CUDA <a href=\"https://www.tensorflow.org/install/install_linux\" rel=\"noreferrer\">installation instructions</a></li>\n<li>Verify that tensorflow is running with GPU <a href=\"https://stackoverflow.com/questions/38009682/how-to-tell-if-tensorflow-is-using-gpu-acceleration-from-inside-python-shell\">check if GPU is working</a></li>\n</ol>\n\n<p><code>sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))</code></p>\n\n<p>OR</p>\n\n<pre><code>from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\n</code></pre>\n\n<p>output will be something like this:</p>\n\n<pre><code>[\n  name: \"/cpu:0\"device_type: \"CPU\",\n  name: \"/gpu:0\"device_type: \"GPU\"\n]\n</code></pre>\n\n<p>Once all this is done your model will run on GPU:</p>\n\n<p>To Check if keras(>=2.1.1) is using GPU:</p>\n\n<pre><code>from keras import backend as K\nK.tensorflow_backend._get_available_gpus()\n</code></pre>\n\n<p>All the best.</p>\n"}, {"title": "How to concatenate two layers in keras?", "question_body": "<p>I have an example of a neural network with two layers. The first layer takes two arguments and has one output. The second should take one argument as result of the first layer and one additional argument. It should looks like this:</p>\n\n<pre><code>x1  x2  x3\n \\  /   /\n  y1   /\n   \\  /\n    y2\n</code></pre>\n\n<p>So, I'd created a model with two layers and tried to merge them but it returns an error: <code>The first layer in a Sequential model must get an \"input_shape\" or \"batch_input_shape\" argument.</code> on the line <code>result.add(merged)</code>.</p>\n\n<p>Model:</p>\n\n<pre class=\"lang-python prettyprint-override\"><code>first = Sequential()\nfirst.add(Dense(1, input_shape=(2,), activation='sigmoid'))\n\nsecond = Sequential()\nsecond.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n\nresult = Sequential()\nmerged = Concatenate([first, second])\nada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\nresult.add(merged)\nresult.compile(optimizer=ada_grad, loss=_loss_tensor, metrics=['accuracy'])\n</code></pre>\n", "link": "https://stackoverflow.com/questions/43196636/how-to-concatenate-two-layers-in-keras", "question_id": 43196636, "accepted_answer_id": 43196972, "answer_body": "<p>You're getting the error because <code>result</code> defined as <code>Sequential()</code> is just a container for the model and you have not defined an input for it. </p>\n\n\n\n<p>Given what you're trying to build set <code>result</code> to take the third input <code>x3</code>.</p>\n\n<pre class=\"lang-python prettyprint-override\"><code>first = Sequential()\nfirst.add(Dense(1, input_shape=(2,), activation='sigmoid'))\n\nsecond = Sequential()\nsecond.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n\nthird = Sequential()\n# of course you must provide the input to result with will be your x3\nthird.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n\n# lets say you add a few more layers to first and second.\n# concatenate them\nmerged = Concatenate([first, second])\n\n# then concatenate the two outputs\n\nresult = Concatenate([merged,  third])\n\nada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\n\nresult.compile(optimizer=ada_grad, loss='binary_crossentropy',\n               metrics=['accuracy'])\n</code></pre>\n\n<p>However, my preferred way of building a model that has this type of input structure would be to use the <a href=\"https://keras.io/getting-started/functional-api-guide/\" rel=\"noreferrer\">functional api</a>.</p>\n\n<p>Here is an implementation of your requirements to get you started:</p>\n\n<pre class=\"lang-python prettyprint-override\"><code>from keras.models import Model\nfrom keras.layers import Concatenate, Dense, LSTM, Input, concatenate\nfrom keras.optimizers import Adagrad\n\nfirst_input = Input(shape=(2, ))\nfirst_dense = Dense(1, )(first_input)\n\nsecond_input = Input(shape=(2, ))\nsecond_dense = Dense(1, )(second_input)\n\nmerge_one = concatenate([first_dense, second_dense])\n\nthird_input = Input(shape=(1, ))\nmerge_two = concatenate([merge_one, third_input])\n\nmodel = Model(inputs=[first_input, second_input, third_input], outputs=merge_two)\nada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\nmodel.compile(optimizer=ada_grad, loss='binary_crossentropy',\n               metrics=['accuracy'])\n</code></pre>\n\n<p><strong>To answer the question in the comments:</strong> </p>\n\n<p>1) How are result and merged connected? Assuming you mean how are they concatenated.</p>\n\n<p>Concatenation works like this:</p>\n\n<pre class=\"lang-python prettyprint-override\"><code>  a        b         c\na b c   g h i    a b c g h i\nd e f   j k l    d e f j k l\n</code></pre>\n\n<p>i.e rows are just joined.</p>\n\n<p>2) Now, <code>x1</code> is input to first, <code>x2</code> is input into second and <code>x3</code> input into third.</p>\n"}, {"title": "Keras Early Stopping", "question_body": "<p>I'm training neural network for my project using Keras. Keras has provided a function for early stopping. May I know what parameters should be observed to avoid my neural network from overfitting by using early stopping?</p>\n", "link": "https://stackoverflow.com/questions/43906048/keras-early-stopping", "question_id": 43906048, "accepted_answer_id": 43906235, "answer_body": "<p><a href=\"https://i.stack.imgur.com/wkK5f.gif\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/wkK5f.gif\" alt=\"early stopping\"></a></p>\n\n<p>Early stopping is basically stopping the training once your loss starts to increase (or in other words validation accuracy starts to decrease). According to <a href=\"https://keras.io/callbacks/#earlystopping\" rel=\"noreferrer\">documents</a> it is used as follows;</p>\n\n<pre><code>keras.callbacks.EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=0,\n                              verbose=0, mode='auto')\n</code></pre>\n\n<p>Values depends on your implementation (problem, batch size etc...) but generally to prevent overfitting I would use;</p>\n\n<ol>\n<li>Monitor the validation loss (need to use cross\nvalidation or at least train/test sets) by setting the <code>monitor</code>\nargument to <code>'val_loss'</code>.</li>\n<li><code>min_delta</code> is a threshold to whether quantify a loss at some epoch as\nimprovement or not. If the difference of loss is below <code>min_delta</code>, it is quantified\nas no improvement. Better to leave it as 0 since we're interested in\nwhen loss becomes worse.</li>\n<li><code>patience</code> argument represents the number of epochs before stopping once your loss starts to increase (stops improving).\nThis depends on your implementation, if you use <em>very small batches</em>\nor a <em>large learning rate</em> your loss <em>zig-zag</em> (accuracy will be more noisy) so better set a\nlarge <code>patience</code> argument. If you use <em>large batches</em> and a <em>small\nlearning rate</em> your loss will be smoother so you can use a\nsmaller <code>patience</code> argument. Either way I'll leave it as 2 so I would\ngive the model more chance.</li>\n<li><code>verbose</code> decides what to print, leave it at default (0).</li>\n<li><code>mode</code> argument depends on what direction your monitored quantity\nhas (is it supposed to be decreasing or increasing), since we monitor the loss, we can use <code>min</code>. But let's leave keras\nhandle that for us and set that to <code>auto</code></li>\n</ol>\n\n<p>So I would use something like this and experiment by plotting the error loss with and without early stopping.</p>\n\n<pre><code>keras.callbacks.EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=2,\n                              verbose=0, mode='auto')\n</code></pre>\n\n<hr>\n\n<p>For possible ambiguity on how callbacks work, I'll try to explain more. Once you call <code>fit(... callbacks=[es])</code> on your model, Keras calls given callback objects predetermined functions. These functions can be called <code>on_train_begin</code>, <code>on_train_end</code>, <code>on_epoch_begin</code>, <code>on_epoch_end</code> and <code>on_batch_begin</code>, <code>on_batch_end</code>. Early stopping callback is called on every epoch end, compares the best monitored value with the current one and stops if conditions are met (how many epochs have past since the observation of the best monitored value and is it more than patience argument, the difference between last value is bigger than min_delta etc..).  </p>\n\n<p>As pointed by @BrentFaust in comments, model's training will continue until either Early Stopping conditions are met or <code>epochs</code> parameter (default=10) in <code>fit()</code> is satisfied. Setting an Early Stopping callback will not make the model to train beyond its <code>epochs</code> parameter. So calling <code>fit()</code> function with a larger <code>epochs</code> value would benefit more from Early Stopping callback.</p>\n"}, {"title": "How to load a model from an HDF5 file in Keras?", "question_body": "<p>How to load a model from an HDF5 file in Keras?</p>\n\n<p>What I tried:</p>\n\n<pre><code>model = Sequential()\n\nmodel.add(Dense(64, input_dim=14, init='uniform'))\nmodel.add(LeakyReLU(alpha=0.3))\nmodel.add(BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64, init='uniform'))\nmodel.add(LeakyReLU(alpha=0.3))\nmodel.add(BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(2, init='uniform'))\nmodel.add(Activation('softmax'))\n\n\nsgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='binary_crossentropy', optimizer=sgd)\n\ncheckpointer = ModelCheckpoint(filepath=\"/weights.hdf5\", verbose=1, save_best_only=True)\nmodel.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose = 2, callbacks=[checkpointer])\n</code></pre>\n\n<p>The above code successfully saves the best model to a file named weights.hdf5. What I want to do is then load that model. The below code shows how I tried to do so:</p>\n\n<pre><code>model2 = Sequential()\nmodel2.load_weights(\"/Users/Desktop/SquareSpace/weights.hdf5\")\n</code></pre>\n\n<p>This is the error I get:</p>\n\n<pre><code>IndexError                                Traceback (most recent call last)\n&lt;ipython-input-101-ec968f9e95c5&gt; in &lt;module&gt;()\n      1 model2 = Sequential()\n----&gt; 2 model2.load_weights(\"/Users/Desktop/SquareSpace/weights.hdf5\")\n\n/Applications/anaconda/lib/python2.7/site-packages/keras/models.pyc in load_weights(self, filepath)\n    582             g = f['layer_{}'.format(k)]\n    583             weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n--&gt; 584             self.layers[k].set_weights(weights)\n    585         f.close()\n    586 \n\nIndexError: list index out of range\n</code></pre>\n", "link": "https://stackoverflow.com/questions/35074549/how-to-load-a-model-from-an-hdf5-file-in-keras", "question_id": 35074549, "accepted_answer_id": 35196851, "answer_body": "<p><code>load_weights</code> only sets the weights of your network. You still need to define its architecture before calling <code>load_weights</code>:</p>\n\n<pre><code>def create_model():\n   model = Sequential()\n   model.add(Dense(64, input_dim=14, init='uniform'))\n   model.add(LeakyReLU(alpha=0.3))\n   model.add(BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None))\n   model.add(Dropout(0.5)) \n   model.add(Dense(64, init='uniform'))\n   model.add(LeakyReLU(alpha=0.3))\n   model.add(BatchNormalization(epsilon=1e-06, mode=0, momentum=0.9, weights=None))\n   model.add(Dropout(0.5))\n   model.add(Dense(2, init='uniform'))\n   model.add(Activation('softmax'))\n   return model\n\ndef train():\n   model = create_model()\n   sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n   model.compile(loss='binary_crossentropy', optimizer=sgd)\n\n   checkpointer = ModelCheckpoint(filepath=\"/tmp/weights.hdf5\", verbose=1, save_best_only=True)\n   model.fit(X_train, y_train, nb_epoch=20, batch_size=16, show_accuracy=True, validation_split=0.2, verbose=2, callbacks=[checkpointer])\n\ndef load_trained_model(weights_path):\n   model = create_model()\n   model.load_weights(weights_path)\n</code></pre>\n"}, {"title": "How to tell Keras stop training based on loss value?", "question_body": "<p>Currently I use the following code:</p>\n\n<pre><code>callbacks = [\n    EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n    ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0),\n]\nmodel.fit(X_train.astype('float32'), Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n      shuffle=True, verbose=1, validation_data=(X_valid, Y_valid),\n      callbacks=callbacks)\n</code></pre>\n\n<p>It tells Keras to stop training when loss didn't improve for 2 epochs. But I want to stop training after loss became smaller than some constant \"THR\":</p>\n\n<pre><code>if val_loss &lt; THR:\n    break\n</code></pre>\n\n<p>I've seen in documentation there are possibility to make your own callback:\n<a href=\"http://keras.io/callbacks/\">http://keras.io/callbacks/</a>\nBut nothing found how to stop training process. I need an advice.</p>\n", "link": "https://stackoverflow.com/questions/37293642/how-to-tell-keras-stop-training-based-on-loss-value", "question_id": 37293642, "accepted_answer_id": 37296168, "answer_body": "<p>I found the answer. I looked into Keras sources and find out code for EarlyStopping. I made my own callback, based on it:</p>\n\n<pre><code>class EarlyStoppingByLossVal(Callback):\n    def __init__(self, monitor='val_loss', value=0.00001, verbose=0):\n        super(Callback, self).__init__()\n        self.monitor = monitor\n        self.value = value\n        self.verbose = verbose\n\n    def on_epoch_end(self, epoch, logs={}):\n        current = logs.get(self.monitor)\n        if current is None:\n            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n\n        if current &lt; self.value:\n            if self.verbose &gt; 0:\n                print(\"Epoch %05d: early stopping THR\" % epoch)\n            self.model.stop_training = True\n</code></pre>\n\n<p>And usage:</p>\n\n<pre><code>callbacks = [\n    EarlyStoppingByLossVal(monitor='val_loss', value=0.00001, verbose=1),\n    # EarlyStopping(monitor='val_loss', patience=2, verbose=0),\n    ModelCheckpoint(kfold_weights_path, monitor='val_loss', save_best_only=True, verbose=0),\n]\nmodel.fit(X_train.astype('float32'), Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n      shuffle=True, verbose=1, validation_data=(X_valid, Y_valid),\n      callbacks=callbacks)\n</code></pre>\n"}, {"title": "Keras, how do I predict after I trained a model?", "question_body": "<p>I'm playing with the reuters-example dataset and it runs fine (my model is trained).  I read about how to save a model, so I could load it later to use again.  But how do I use this saved model to predict a new text?  Do I use <code>models.predict()</code>?</p>\n\n<p>Do I have to prepare this text in a special way?</p>\n\n<p>I tried it with</p>\n\n<pre><code>import keras.preprocessing.text\n\ntext = np.array(['this is just some random, stupid text'])\nprint(text.shape)\n\ntk = keras.preprocessing.text.Tokenizer(\n        nb_words=2000,\n        filters=keras.preprocessing.text.base_filter(),\n        lower=True,\n        split=\" \")\n\ntk.fit_on_texts(text)\npred = tk.texts_to_sequences(text)\nprint(pred)\n\nmodel.predict(pred)\n</code></pre>\n\n<p>But I always get</p>\n\n<pre><code>(1L,)\n[[2, 4, 1, 6, 5, 7, 3]]\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n&lt;ipython-input-83-42d744d811fb&gt; in &lt;module&gt;()\n      7 print(pred)\n      8 \n----&gt; 9 model.predict(pred)\n\nC:\\Users\\bkey\\Anaconda2\\lib\\site-packages\\keras\\models.pyc in predict(self, x, batch_size, verbose)\n    457         if self.model is None:\n    458             self.build()\n--&gt; 459         return self.model.predict(x, batch_size=batch_size, verbose=verbose)\n    460 \n    461     def predict_on_batch(self, x):\n\nC:\\Users\\bkey\\Anaconda2\\lib\\site-packages\\keras\\engine\\training.pyc in predict(self, x, batch_size, verbose)\n   1132         x = standardize_input_data(x, self.input_names,\n   1133                                    self.internal_input_shapes,\n-&gt; 1134                                    check_batch_dim=False)\n   1135         if self.stateful:\n   1136             if x[0].shape[0] &gt; batch_size and x[0].shape[0] % batch_size != 0:\n\nC:\\Users\\bkey\\Anaconda2\\lib\\site-packages\\keras\\engine\\training.pyc in standardize_input_data(data, names, shapes, check_batch_dim, exception_prefix)\n     79     for i in range(len(names)):\n     80         array = arrays[i]\n---&gt; 81         if len(array.shape) == 1:\n     82             array = np.expand_dims(array, 1)\n     83             arrays[i] = array\n\nAttributeError: 'list' object has no attribute 'shape'\n</code></pre>\n\n<p>Do you have any recommendations as to how to make predictions with a trained model?</p>\n", "link": "https://stackoverflow.com/questions/37891954/keras-how-do-i-predict-after-i-trained-a-model", "question_id": 37891954, "accepted_answer_id": null}, {"title": "Loading a trained Keras model and continue training", "question_body": "<p>I was wondering if it was possible to save a partly trained Keras model and continue the training after loading the model again.</p>\n\n<p>The reason for this is that I will have more training data in the future and I do not want to retrain the whole model again.</p>\n\n<p>The functions which I am using are:</p>\n\n<pre><code>#Partly train model\nmodel.fit(first_training, first_classes, batch_size=32, nb_epoch=20)\n\n#Save partly trained model\nmodel.save('partly_trained.h5')\n\n#Load partly trained model\nfrom keras.models import load_model\nmodel = load_model('partly_trained.h5')\n\n#Continue training\nmodel.fit(second_training, second_classes, batch_size=32, nb_epoch=20)\n</code></pre>\n\n<hr>\n\n<p><strong>Edit 1: added fully working example</strong></p>\n\n<p>With the first dataset after 10 epochs the loss of the last epoch will be 0.0748 and the accuracy 0.9863.</p>\n\n<p>After saving, deleting and reloading the model the loss and accuracy of the model trained on the second dataset will be 0.1711 and 0.9504 respectively.</p>\n\n<p>Is this caused by the new training data or by a completely re-trained model?</p>\n\n<pre><code>\"\"\"\nModel by: http://machinelearningmastery.com/\n\"\"\"\n# load (downloaded if needed) the MNIST dataset\nimport numpy\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import np_utils\nfrom keras.models import load_model\nnumpy.random.seed(7)\n\ndef baseline_model():\n    model = Sequential()\n    model.add(Dense(num_pixels, input_dim=num_pixels, init='normal', activation='relu'))\n    model.add(Dense(num_classes, init='normal', activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\nif __name__ == '__main__':\n    # load data\n    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n\n    # flatten 28*28 images to a 784 vector for each image\n    num_pixels = X_train.shape[1] * X_train.shape[2]\n    X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n    X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n    # normalize inputs from 0-255 to 0-1\n    X_train = X_train / 255\n    X_test = X_test / 255\n    # one hot encode outputs\n    y_train = np_utils.to_categorical(y_train)\n    y_test = np_utils.to_categorical(y_test)\n    num_classes = y_test.shape[1]\n\n    # build the model\n    model = baseline_model()\n\n    #Partly train model\n    dataset1_x = X_train[:3000]\n    dataset1_y = y_train[:3000]\n    model.fit(dataset1_x, dataset1_y, nb_epoch=10, batch_size=200, verbose=2)\n\n    # Final evaluation of the model\n    scores = model.evaluate(X_test, y_test, verbose=0)\n    print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n\n    #Save partly trained model\n    model.save('partly_trained.h5')\n    del model\n\n    #Reload model\n    model = load_model('partly_trained.h5')\n\n    #Continue training\n    dataset2_x = X_train[3000:]\n    dataset2_y = y_train[3000:]\n    model.fit(dataset2_x, dataset2_y, nb_epoch=10, batch_size=200, verbose=2)\n    scores = model.evaluate(X_test, y_test, verbose=0)\n    print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n</code></pre>\n", "link": "https://stackoverflow.com/questions/42666046/loading-a-trained-keras-model-and-continue-training", "question_id": 42666046, "accepted_answer_id": 42670479, "answer_body": "<p>Actually - <code>model.save</code> saves all information need for restarting training in your case. The only thing which could be spoiled by reloading model is your optimizer state. To check that - try to <code>save</code> and reload model and train it on training data.</p>\n"}, {"title": "Role of &quot;Flatten&quot; in Keras", "question_body": "<p>I am trying to understand the role of the <code>Flatten</code> function in Keras. Below is my code, which is a simple two-layer network. It takes in 2-dimensional data of shape (3, 2), and outputs 1-dimensional data of shape (1, 4):</p>\n\n<pre><code>model = Sequential()\nmodel.add(Dense(16, input_shape=(3, 2)))\nmodel.add(Activation('relu'))\nmodel.add(Flatten())\nmodel.add(Dense(4))\nmodel.compile(loss='mean_squared_error', optimizer='SGD')\n\nx = np.array([[[1, 2], [3, 4], [5, 6]]])\n\ny = model.predict(x)\n\nprint y.shape\n</code></pre>\n\n<p>This prints out that <code>y</code> has shape (1, 4). However, if I remove the <code>Flatten</code> line, then it prints out that <code>y</code> has shape (1, 3, 4).</p>\n\n<p>I don't understand this. From my understanding of neural networks, the <code>model.add(Dense(16, input_shape=(3, 2)))</code> function is creating a hidden fully-connected layer, with 16 nodes. Each of these nodes is connected to each of the 3x2 input elements. Therefore, the 16 nodes at the output of this first layer are already \"flat\". So, the output shape of the first layer should be (1, 16). Then, the second layer takes this as an input, and outputs data of shape (1, 4).</p>\n\n<p>So if the output of the first layer is already \"flat\" and of shape (1, 16), why do I need to further flatten it?</p>\n\n<p>Thanks!</p>\n", "link": "https://stackoverflow.com/questions/43237124/role-of-flatten-in-keras", "question_id": 43237124, "accepted_answer_id": 43237727, "answer_body": "<p>if you read a documentation of <a href=\"https://keras.io/layers/core/#dense\" rel=\"noreferrer\"><code>Dense</code></a> here you will see that:</p>\n\n<pre><code>Dense(16, input_shape=(5,3))\n</code></pre>\n\n<p>would result in a <code>Dense</code> network with 3 inputs and 16 outputs which would be applied independently for each of 5 steps. So if <code>D(x)</code> transforms 3 dimensional vector to 16-d vector what you'll get as output from your layer would be a sequence of vectors: <code>[D(x[0,:], D(x[1,:],..., D(x[4,:]]</code> with shape <code>(5, 16)</code>. In order to have the behaviour you specify you may first <code>Flatten</code> your input to a 15-d vector and then apply <code>Dense</code>:</p>\n\n<pre><code>model = Sequential()\nmodel.add(Flatten(input_shape=(3, 2)))\nmodel.add(Dense(16))\nmodel.add(Activation('relu'))\nmodel.add(Dense(4))\nmodel.compile(loss='mean_squared_error', optimizer='SGD')\n</code></pre>\n\n<p><strong>EDIT:</strong>\nAs some people struggled to understand - here you have an explaining image:</p>\n\n<p><a href=\"https://i.stack.imgur.com/Wk8eV.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/Wk8eV.png\" alt=\"enter image description here\"></a></p>\n"}, {"title": "How do I install Keras and Theano in Anaconda Python on Windows?", "question_body": "<p>I am trying to work on neural networks in Python using the following Keras packages:</p>\n\n<pre><code>from keras.utils import np_utils\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D\nfrom keras.optimizers import SGD\n</code></pre>\n\n<p>But, I am getting the following error:</p>\n\n<pre><code> 15 import theano\n ---&gt; 16 from theano import gof\n 17 from theano.compat.python2x import partial\n 18 import theano.compile.mode\n ImportError: cannot import name gof\n</code></pre>\n\n<p>Installing installed <code>conda install keras</code>. Later I tried to use <code>pip install Theano</code>, but it did not work. I Tried to install using <code>pip install git</code>, but I am getting this error: <code>cannot find command git.</code> So I installed Git and I set the environment variables.</p>\n\n<p>So, is there any procedure to install these packages?</p>\n", "link": "https://stackoverflow.com/questions/34097988/how-do-i-install-keras-and-theano-in-anaconda-python-on-windows", "question_id": 34097988, "accepted_answer_id": 34975902, "answer_body": "<p>It is my solution for the same problem</p>\n\n<ul>\n<li>Install <a href=\"http://tdm-gcc.tdragon.net/\">TDM GCC</a> x64.</li>\n<li>Install <a href=\"https://www.continuum.io/downloads\">Anaconda</a> x64.</li>\n<li>Open the Anaconda prompt</li>\n<li>Run <code>conda update conda</code></li>\n<li>Run <code>conda update --all</code></li>\n<li>Run <code>conda install mingw libpython</code></li>\n<li>Install the latest version of Theano,\n<code>pip install git+git://github.com/Theano/Theano.git</code></li>\n<li>Run <code>pip install git+git://github.com/fchollet/keras.git</code></li>\n</ul>\n"}, {"title": "How to fix &#39;Object arrays cannot be loaded when allow_pickle=False&#39; for imdb.load_data() function?", "question_body": "<p>I'm trying to implement the binary classification example using the IMDb dataset in <strong>Google Colab</strong>. I have implemented this model before. But when I tried to do it again after a few days, it returned a value error:'Object arrays cannot be loaded when allow_pickle=False' for the load_data() function.</p>\n\n<p>I have already tried solving this, referring to an existing answer for a similar problem: <a href=\"https://stackoverflow.com/questions/55824625/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-in-the-sketc?answertab=votes#tab-top\">How to fix &#39;Object arrays cannot be loaded when allow_pickle=False&#39; in the sketch_rnn algorithm</a>\nBut turns out that just adding an allow_pickle argument isn't sufficient.</p>\n\n<p>My code:</p>\n\n<pre><code>from keras.datasets import imdb\n(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n</code></pre>\n\n<p>The error:</p>\n\n<pre><code>ValueError                                Traceback (most recent call last)\n&lt;ipython-input-1-2ab3902db485&gt; in &lt;module&gt;()\n      1 from keras.datasets import imdb\n----&gt; 2 (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n\n2 frames\n/usr/local/lib/python3.6/dist-packages/keras/datasets/imdb.py in load_data(path, num_words, skip_top, maxlen, seed, start_char, oov_char, index_from, **kwargs)\n     57                     file_hash='599dadb1135973df5b59232a0e9a887c')\n     58     with np.load(path) as f:\n---&gt; 59         x_train, labels_train = f['x_train'], f['y_train']\n     60         x_test, labels_test = f['x_test'], f['y_test']\n     61 \n\n/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py in __getitem__(self, key)\n    260                 return format.read_array(bytes,\n    261                                          allow_pickle=self.allow_pickle,\n--&gt; 262                                          pickle_kwargs=self.pickle_kwargs)\n    263             else:\n    264                 return self.zip.read(key)\n\n/usr/local/lib/python3.6/dist-packages/numpy/lib/format.py in read_array(fp, allow_pickle, pickle_kwargs)\n    690         # The array contained Python objects. We need to unpickle the data.\n    691         if not allow_pickle:\n--&gt; 692             raise ValueError(\"Object arrays cannot be loaded when \"\n    693                              \"allow_pickle=False\")\n    694         if pickle_kwargs is None:\n\nValueError: Object arrays cannot be loaded when allow_pickle=False\n</code></pre>\n", "link": "https://stackoverflow.com/questions/55890813/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-for-imdb-loa", "question_id": 55890813, "accepted_answer_id": 56243777, "answer_body": "<p>Here's a trick to force <code>imdb.load_data</code> to allow pickle by, in your notebook, replacing this line:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n</code></pre>\n\n<p>by this:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\n# save np.load\nnp_load_old = np.load\n\n# modify the default parameters of np.load\nnp.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n\n# call load_data with allow_pickle implicitly set to true\n(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n\n# restore np.load for future normal usage\nnp.load = np_load_old\n</code></pre>\n"}, {"title": "Keras: Difference between Kernel and Activity regularizers", "question_body": "<p>I have noticed that <em>weight_regularizer</em> is no more available in Keras and that, in its place, there are <em>activity</em> and <em>kernel</em> regularizer. \nI would like to know:</p>\n\n<ul>\n<li>What are the main differences between <em>kernel</em> and <em>activity</em> regularizers?</li>\n<li>Could I use <em>activity_regularizer</em> in place of <em>weight_regularizer</em>?</li>\n</ul>\n", "link": "https://stackoverflow.com/questions/44495698/keras-difference-between-kernel-and-activity-regularizers", "question_id": 44495698, "accepted_answer_id": 44496213, "answer_body": "<p>The activity regularizer works as a function of the output of the net, and is mostly used to regularize hidden units, while weight_regularizer, as the name says, works on the weights, making them decay. Basically you can express the regularization loss as a function of the output (<code>activity_regularizer</code>) or of the weights (<code>weight_regularizer</code>). </p>\n\n<p>The new <code>kernel_regularizer</code> replaces <code>weight_regularizer</code> - although it's not very clear from the documentation.</p>\n\n<p>From the definition of <code>kernel_regularizer</code>:</p>\n\n<blockquote>\n  <p>kernel_regularizer: Regularizer function applied to\n              the <code>kernel</code> weights matrix\n              (see regularizer).</p>\n</blockquote>\n\n<p>And <code>activity_regularizer</code>:</p>\n\n<blockquote>\n  <p>activity_regularizer: Regularizer function applied to\n              the output of the layer (its \"activation\").\n              (see regularizer).</p>\n</blockquote>\n\n<p><strong>Important Edit</strong>: Note that there is a bug in the <em>activity_regularizer</em> that was <strong>only fixed in version 2.1.4 of Keras</strong> (at least with Tensorflow backend). Indeed, in the older versions, the activity regularizer function is applied to the input of the layer, instead of being applied to the output (the actual activations of the layer, as intended). So beware if you are using an older version of Keras (before 2.1.4), activity regularization may probably not work as intended.</p>\n\n<p>You can see the commit on <a href=\"https://github.com/keras-team/keras/commits/master?after=75114feeac5ee6aa7679802ce7e5172c63565e2c+279\" rel=\"noreferrer\">GitHub</a></p>\n\n<p><a href=\"https://i.stack.imgur.com/EQSyd.png\" rel=\"noreferrer\">Five months ago Fran\u00e7ois Chollet provided a fix to the activity regularizer, that was then included in Keras 2.1.4</a></p>\n"}, {"title": "Using Keras &amp; Tensorflow with AMD GPU", "question_body": "<p>I'm starting to learn Keras, which I believe is a layer on top of Tensorflow and Theano.  However, I only have access to AMD GPUs such as the AMD R9 280X.</p>\n\n<p>How can I setup my Python environment such that I can make use of my AMD GPUs through Keras/Tensorflow support for OpenCL?</p>\n\n<p>I'm running on OSX.</p>\n", "link": "https://stackoverflow.com/questions/37892784/using-keras-tensorflow-with-amd-gpu", "question_id": 37892784, "accepted_answer_id": null}, {"title": "How to get reproducible results in keras", "question_body": "<p>I get different results (test accuracy) every time I run the <code>imdb_lstm.py</code> example from Keras framework (<a href=\"https://github.com/fchollet/keras/blob/master/examples/imdb_lstm.py\">https://github.com/fchollet/keras/blob/master/examples/imdb_lstm.py</a>)\nThe code contains <code>np.random.seed(1337)</code> in the top, before any keras imports. It should prevent it from generating different numbers for every run. What am I missing?  </p>\n\n<p>UPDATE: How to repro:  </p>\n\n<ol>\n<li>Install Keras (<a href=\"http://keras.io/\">http://keras.io/</a>)   </li>\n<li>Execute <a href=\"https://github.com/fchollet/keras/blob/master/examples/imdb_lstm.py\">https://github.com/fchollet/keras/blob/master/examples/imdb_lstm.py</a>  a few times. It will train the model and output test accuracy.<br>\nExpected result: Test accuracy is the same on every run.<br>\nActual result: Test accuracy is different on every run.</li>\n</ol>\n\n<p>UPDATE2: I'm running it on Windows 8.1 with MinGW/msys, module versions:<br>\ntheano 0.7.0<br>\nnumpy 1.8.1<br>\nscipy 0.14.0c1</p>\n\n<p>UPDATE3: I narrowed the problem down a bit. If I run the example with GPU (set theano flag device=gpu0) then I get different test accuracy every time, but if I run it on CPU then everything works as expected. My graphics card: NVIDIA GeForce GT 635)</p>\n", "link": "https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras", "question_id": 32419510, "accepted_answer_id": null}, {"title": "How does Keras handle multilabel classification?", "question_body": "<p>I am unsure how to interpret the default behavior of Keras in the following situation:</p>\n\n<p>My Y (ground truth) was set up using scikit-learn's <code>MultilabelBinarizer</code>().</p>\n\n<p>Therefore, to give a random example, one row of my <code>y</code> column is one-hot encoded as such:\n<code>[0,0,0,1,0,1,0,0,0,0,1]</code>.</p>\n\n<p>So I have 11 classes that could be predicted, and more than one can be true; hence the multilabel nature of the problem.  There are three labels for this particular sample.</p>\n\n<p>I train the model as I would for a non multilabel problem (business as usual) and I get no errors.</p>\n\n<pre><code>from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.optimizers import SGD\n\nmodel = Sequential()\nmodel.add(Dense(5000, activation='relu', input_dim=X_train.shape[1]))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(600, activation='relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(y_train.shape[1], activation='softmax'))\n\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=sgd,\n              metrics=['accuracy',])\n\nmodel.fit(X_train, y_train,epochs=5,batch_size=2000)\n\nscore = model.evaluate(X_test, y_test, batch_size=2000)\nscore\n</code></pre>\n\n<p>What does Keras do when it encounters my <code>y_train</code> and sees that it is \"multi\" one-hot encoded, meaning there is more than one 'one' present in each row of <code>y_train</code>?  Basically, does Keras automatically perform multilabel classification?  Any differences in the interpretation of the scoring metrics?</p>\n", "link": "https://stackoverflow.com/questions/44164749/how-does-keras-handle-multilabel-classification", "question_id": 44164749, "accepted_answer_id": null}, {"title": "How to check which version of Keras is installed?", "question_body": "<p>Question is the same as the title says. </p>\n\n<p>I prefer not to open Python and I use either MacOS or Ubuntu.</p>\n", "link": "https://stackoverflow.com/questions/46086030/how-to-check-which-version-of-keras-is-installed", "question_id": 46086030, "accepted_answer_id": 46086039, "answer_body": "<p>Python library authors put the version number in <code>&lt;module&gt;.__version__</code>. You can print it by running this on the command line:</p>\n\n<pre><code>python -c 'import keras; print(keras.__version__)'\n</code></pre>\n\n<p>If it's Windows terminal, enclose snippet with double-quotes like below</p>\n\n<pre><code>python -c \"import keras; print(keras.__version__)\"\n</code></pre>\n"}, {"title": "Dimension of shape in conv1D", "question_body": "<p>I have tried to build a CNN with one layer, but I have some problem with it.\nIndeed, the compilator says me that</p>\n\n<blockquote>\n  <p>ValueError: Error when checking model input: expected conv1d_1_input\n  to have 3 dimensions, but got array with shape (569, 30)</p>\n</blockquote>\n\n<p>This is the code</p>\n\n<pre><code>import numpy\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv1D\nnumpy.random.seed(7)\ndatasetTraining = numpy.loadtxt(\"CancerAdapter.csv\",delimiter=\",\")\nX = datasetTraining[:,1:31]\nY = datasetTraining[:,0]\ndatasetTesting = numpy.loadtxt(\"CancereEvaluation.csv\",delimiter=\",\")\nX_test = datasetTraining[:,1:31]\nY_test = datasetTraining[:,0]\nmodel = Sequential()\nmodel.add(Conv1D(2,2,activation='relu',input_shape=X.shape))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X, Y, epochs=150, batch_size=5)\nscores = model.evaluate(X_test, Y_test)\nprint(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n</code></pre>\n", "link": "https://stackoverflow.com/questions/43396572/dimension-of-shape-in-conv1d", "question_id": 43396572, "accepted_answer_id": 43399308, "answer_body": "<p><strong>td; lr</strong> you need  to reshape you data to have a <em>spatial</em> dimension for <code>Conv1d</code> to make sense:</p>\n\n<pre><code>X = np.expand_dims(X, axis=2) # reshape (569, 30) to (569, 30, 1) \n# now input can be set as \nmodel.add(Conv1D(2,2,activation='relu',input_shape=(30, 1))\n</code></pre>\n\n<p>Essentially reshaping a dataset that looks like this:</p>\n\n<pre><code>features    \n.8, .1, .3  \n.2, .4, .6  \n.7, .2, .1  \n</code></pre>\n\n<p>To:</p>\n\n<pre><code>[[.8\n.1\n.3],\n\n[.2,\n .4,\n .6\n ],\n\n[.3,\n .6\n .1]]\n</code></pre>\n\n<p><strong>Explanation and examples</strong></p>\n\n<p>Normally convolution works over spatial dimensions. Kernel is \"convolved\" over the dimension producing a tensor. In the case of Conv1D, the kernel is passed of over the 'steps' dimension of every example. </p>\n\n<p>You will see Conv1D used for in NLP where the <code>steps</code> is number of words in the sentence (padded to some fixed maximum length). The words would might be encoded as vectors of length 4. </p>\n\n<p>Here is an example sentence:</p>\n\n<pre><code>jack   .1   .3   -.52   |\nis     .05  .8,  -.7    |&lt;--- kernel is `convolving` along this dimension.\na      .5   .31  -.2    |\nboy    .5   .8   -.4   \\|/\n</code></pre>\n\n<p>And the way we would set the input to the conv in this case:</p>\n\n<pre><code>maxlen = 4\ninput_dim = 3\nmodel.add(Conv1D(2,2,activation='relu',input_shape=(maxlen, input_dim))\n</code></pre>\n\n<p>In your case you will treat the features as spatial dimension with each feature having length 1. (see below)</p>\n\n<p>Here would be an example from your dataset</p>\n\n<pre><code>att1   .04    |\natt2   .05    |  &lt; -- kernel convolving along this dimension\natt3   .1     |       notice the features have length 1. each\natt4   .5    \\|/      example have these 4 featues.\n</code></pre>\n\n<p>And we would set the Conv1D example as:</p>\n\n<pre><code>maxlen = num_features = 4 # this would be 30 in your case\ninput_dim = 1 # since this is the length of _each_ feature (as shown above)\n\nmodel.add(Conv1D(2,2,activation='relu',input_shape=(maxlen, input_dim))\n</code></pre>\n\n<p>As you see your dataset has to be reshaped in to (569, 30, 1) \nuse:</p>\n\n<pre><code>X = np.expand_dims(X, axis=2) # reshape (569, 30, 1) \n# now input can be set as \nmodel.add(Conv1D(2,2,activation='relu',input_shape=(30, 1))\n</code></pre>\n\n<p>Here is a full-fledged example that you can run (I'll use the <a href=\"https://keras.io/getting-started/functional-api-guide/\" rel=\"noreferrer\">Functional API</a>)</p>\n\n<pre><code>from keras.models import Model\nfrom keras.layers import Conv1D, Dense, MaxPool1D, Flatten, Input\nimport numpy as np\n\ninp =  Input(shape=(5, 1))\nconv = Conv1D(filters=2, kernel_size=2)(inp)\npool = MaxPool1D(pool_size=2)(conv)\nflat = Flatten()(pool)\ndense = Dense(1)(flat)\nmodel = Model(inp, dense)\nmodel.compile(loss='mse', optimizer='adam')\n\nprint(model.summary())\n\n# get some data\nX = np.expand_dims(np.random.randn(10, 5), axis=2)\ny = np.random.randn(10, 1)\n\n# fit model\nmodel.fit(X, y)\n</code></pre>\n"}, {"title": "Keras: the difference between LSTM dropout and LSTM recurrent dropout", "question_body": "<p>From the Keras documentation:</p>\n\n<p>dropout: Float between 0 and 1. Fraction of the units to drop for the\n linear transformation of the inputs.</p>\n\n<p>recurrent_dropout: Float between 0 and 1. Fraction of the units to\n drop for the linear transformation of the recurrent state.</p>\n\n<p>Can anyone point to where on the image below each dropout happens?</p>\n\n<p><a href=\"https://i.stack.imgur.com/DS97N.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/DS97N.png\" alt=\"enter image description here\"></a></p>\n", "link": "https://stackoverflow.com/questions/44924690/keras-the-difference-between-lstm-dropout-and-lstm-recurrent-dropout", "question_id": 44924690, "accepted_answer_id": 44929759, "answer_body": "<p>I suggest taking a look at (the first part of) <a href=\"https://arxiv.org/pdf/1512.05287.pdf\" rel=\"noreferrer\">this paper</a>. Regular dropout is applied on the inputs and/or the outputs, meaning the vertical arrows from <code>x_t</code> and to <code>h_t</code>. In your case, if you add it as an argument to your layer, it will mask the inputs; you can add a Dropout layer after your recurrent layer to mask the outputs as well. Recurrent dropout masks (or \"drops\") the connections between the recurrent units; that would be the horizontal arrows in your picture.</p>\n\n<p>This picture is taken from the paper above. On the left, regular dropout on inputs and outputs. On the right, regular dropout PLUS recurrent dropout:</p>\n\n<p><a href=\"https://i.stack.imgur.com/fWDtw.png\" rel=\"noreferrer\"><img src=\"https://i.stack.imgur.com/fWDtw.png\" alt=\"This picture is taken from the paper above. On the left, regular dropout on inputs and outputs. On the right, regular dropout PLUS recurrent dropout.\"></a></p>\n\n<p>(Ignore the colour of the arrows in this case; in the paper they are making a further point of keeping the same dropout masks at each timestep)</p>\n"}, {"title": "NaN loss when training regression network", "question_body": "<p>I have a data matrix in \"one-hot encoding\" (all ones and zeros) with 260,000 rows and 35 columns.  I am using Keras to train a simple neural network to predict a continuous variable.  The code to make the network is the following:</p>\n\n<pre><code>model = Sequential()\nmodel.add(Dense(1024, input_shape=(n_train,)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(1))\n\nsgd = SGD(lr=0.01, nesterov=True);\n#rms = RMSprop()\n#model.compile(loss='categorical_crossentropy', optimizer=rms, metrics=['accuracy'])\nmodel.compile(loss='mean_absolute_error', optimizer=sgd)\nmodel.fit(X_train, Y_train, batch_size=32, nb_epoch=3, verbose=1, validation_data=(X_test,Y_test), callbacks=[EarlyStopping(monitor='val_loss', patience=4)] )\n</code></pre>\n\n<p>However, during the training process, I see the loss decrease nicely, but during the middle of the second epoch, it goes to nan:</p>\n\n<pre><code>Train on 260000 samples, validate on 64905 samples\nEpoch 1/3\n260000/260000 [==============================] - 254s - loss: 16.2775 - val_loss:\n 13.4925\nEpoch 2/3\n 88448/260000 [=========&gt;....................] - ETA: 161s - loss: nan\n</code></pre>\n\n<p>I tried using <code>RMSProp</code> instead of <code>SGD</code>, I tried <code>tanh</code> instead of <code>relu</code>, I tried with and without dropout, all to no avail.  I tried with a smaller model, i.e. with only one hidden layer, and same issue (it becomes nan at a different point).  However, it does work with less features, i.e. if there are only 5 columns, and gives quite good predictions. It seems to be there is some kind of overflow, but I can't imagine why--the loss is not unreasonably large at all.  </p>\n\n<p>Python version 2.7.11, running on a linux machine, CPU only.  I tested it with the latest version of Theano, and I also get Nans, so I tried going to Theano 0.8.2 and have the same problem.  With the latest version of Keras has the same problem, and also with the 0.3.2 version.  </p>\n", "link": "https://stackoverflow.com/questions/37232782/nan-loss-when-training-regression-network", "question_id": 37232782, "accepted_answer_id": 37242531, "answer_body": "<p>Regression with neural networks is hard to get working because the output is unbounded, so you are especially prone to the <a href=\"http://neuralnetworksanddeeplearning.com/chap5.html\">exploding gradients problem</a> (the likely cause of the nans).  </p>\n\n<p>Historically, one key solution to exploding gradients was to reduce the learning rate, but with the advent of per-parameter adaptive learning rate algorithms like Adam, you no longer need to set a learning rate to get good performance.  There is very little reason to use SGD with momentum anymore unless you're a neural network fiend and know how to tune the learning schedule.</p>\n\n<p>Here are some things you could potentially try:</p>\n\n<ol>\n<li><p>Normalize your outputs by <a href=\"https://en.wikipedia.org/wiki/Quantile_normalization\">quantile normalizing</a> or <a href=\"https://en.wikipedia.org/wiki/Standard_score\">z scoring</a>.  To be rigorous, compute this transformation on the training data, not on the entire dataset.  For example, with quantile normalization, if an example is in the 60th percentile of the training set, it gets a value of 0.6.  (You can also shift the quantile normalized values down by 0.5 so that the 0th percentile is -0.5 and the 100th percentile is +0.5).</p></li>\n<li><p>Add regularization, either by increasing the dropout rate or adding L1 and L2 penalties to the weights.  L1 regularization is analogous to feature selection, and since you said that reducing the number of features to 5 gives good performance, L1 may also.</p></li>\n<li><p>If these still don't help, reduce the size of your network.  This is not always the best idea since it can harm performance, but in your case you have a large number of first-layer neurons (1024) relative to input features (35) so it may help.</p></li>\n<li><p>Increase the batch size from 32 to 128.  128 is fairly standard and could potentially increase the stability of the optimization.</p></li>\n</ol>\n"}, {"title": "How to compute Receiving Operating Characteristic (ROC) and AUC in keras?", "question_body": "<p>I have a multi output(200) binary classification model which I wrote in keras. </p>\n\n<p>In this model I want to add additional metrics such as ROC and AUC but to my knowledge keras dosen't have in-built ROC and AUC metric functions. </p>\n\n<p>I tried to import ROC, AUC functions from scikit-learn</p>\n\n<pre><code>from sklearn.metrics import roc_curve, auc\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n.\n.\n.\nmodel.add(Dense(200, activation='relu'))\nmodel.add(Dense(300, activation='relu'))\nmodel.add(Dense(400, activation='relu'))\nmodel.add(Dense(300, activation='relu'))\nmodel.add(Dense(200,init='normal', activation='softmax')) #outputlayer\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy','roc_curve','auc'])\n</code></pre>\n\n<p>but it's giving this error:</p>\n\n<blockquote>\n  <p>Exception: Invalid metric: roc_curve</p>\n</blockquote>\n\n<p>How should I add ROC, AUC to keras?</p>\n", "link": "https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras", "question_id": 41032551, "accepted_answer_id": null}, {"title": "How do I check if keras is using gpu version of tensorflow?", "question_body": "<p>When I run a keras script, I get the following output:</p>\n\n<pre><code>Using TensorFlow backend.\n2017-06-14 17:40:44.621761: W \ntensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow \nlibrary wasn't compiled to use SSE4.1 instructions, but these are \navailable on your machine and could speed up CPU computations.\n2017-06-14 17:40:44.621783: W \ntensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow \nlibrary wasn't compiled to use SSE4.2 instructions, but these are \navailable on your machine and could speed up CPU computations.\n2017-06-14 17:40:44.621788: W \ntensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow \nlibrary wasn't compiled to use AVX instructions, but these are \navailable on your machine and could speed up CPU computations.\n2017-06-14 17:40:44.621791: W \ntensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow \nlibrary wasn't compiled to use AVX2 instructions, but these are \navailable on your machine and could speed up CPU computations.\n2017-06-14 17:40:44.621795: W \ntensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow \nlibrary wasn't compiled to use FMA instructions, but these are \navailable \non your machine and could speed up CPU computations.\n2017-06-14 17:40:44.721911: I \ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful \nNUMA node read from SysFS had negative value (-1), but there must be \nat least one NUMA node, so returning NUMA node zero\n2017-06-14 17:40:44.722288: I \ntensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 \nwith properties: \nname: GeForce GTX 850M\nmajor: 5 minor: 0 memoryClockRate (GHz) 0.9015\npciBusID 0000:0a:00.0\nTotal memory: 3.95GiB\nFree memory: 3.69GiB\n2017-06-14 17:40:44.722302: I \ntensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n2017-06-14 17:40:44.722307: I \ntensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n2017-06-14 17:40:44.722312: I \ntensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating \nTensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 850M, \npci bus id: 0000:0a:00.0)\n</code></pre>\n\n<p>What does this mean? Am I using GPU or CPU version of tensorflow?</p>\n\n<p>Before installing keras, I was working with the GPU version of tensorflow. </p>\n\n<p>Also <code>sudo pip3 list</code> shows <code>tensorflow-gpu(1.1.0)</code> and nothing like <code>tensorflow-cpu</code>.</p>\n\n<p>Running the command mentioned on [this stackoverflow question], gives the following:</p>\n\n<pre><code>The TensorFlow library wasn't compiled to use SSE4.1 instructions, \nbut these are available on your machine and could speed up CPU \ncomputations.\n2017-06-14 17:53:31.424793: W \ntensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow \nlibrary wasn't compiled to use SSE4.2 instructions, but these are \navailable on your machine and could speed up CPU computations.\n2017-06-14 17:53:31.424803: W \ntensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow \nlibrary wasn't compiled to use AVX instructions, but these are \navailable on your machine and could speed up CPU computations.\n2017-06-14 17:53:31.424812: W \ntensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow \nlibrary wasn't compiled to use AVX2 instructions, but these are \navailable on your machine and could speed up CPU computations.\n2017-06-14 17:53:31.424820: W \ntensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow \nlibrary wasn't compiled to use FMA instructions, but these are \navailable on your machine and could speed up CPU computations.\n2017-06-14 17:53:31.540959: I \ntensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful \nNUMA node read from SysFS had negative value (-1), but there must be \nat least one NUMA node, so returning NUMA node zero\n2017-06-14 17:53:31.541359: I \ntensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 \nwith properties: \nname: GeForce GTX 850M\nmajor: 5 minor: 0 memoryClockRate (GHz) 0.9015\npciBusID 0000:0a:00.0\nTotal memory: 3.95GiB\nFree memory: 128.12MiB\n2017-06-14 17:53:31.541407: I \ntensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n2017-06-14 17:53:31.541420: I \ntensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n2017-06-14 17:53:31.541441: I \ntensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating \nTensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX 850M, \npci bus id: 0000:0a:00.0)\n2017-06-14 17:53:31.547902: E \ntensorflow/stream_executor/cuda/cuda_driver.cc:893] failed to \nallocate 128.12M (134348800 bytes) from device: \nCUDA_ERROR_OUT_OF_MEMORY\nDevice mapping:\n/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: GeForce \nGTX 850M, pci bus id: 0000:0a:00.0\n2017-06-14 17:53:31.549482: I \ntensorflow/core/common_runtime/direct_session.cc:257] Device \nmapping:\n/job:localhost/replica:0/task:0/gpu:0 -&gt; device: 0, name: GeForce \nGTX 850M, pci bus id: 0000:0a:00.0\n</code></pre>\n", "link": "https://stackoverflow.com/questions/44544766/how-do-i-check-if-keras-is-using-gpu-version-of-tensorflow", "question_id": 44544766, "accepted_answer_id": 44547144, "answer_body": "<p>You are using the GPU version. You can list the available tensorflow devices with (also check <a href=\"https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow\">this</a> question):</p>\n\n<pre><code>from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\n</code></pre>\n\n<p>In your case both the cpu and gpu are available, if you use the cpu version of tensorflow the gpu will not be listed. In your case, without setting your tensorflow device (<code>with tf.device(\"..\")</code>), tensorflow will automatically pick your gpu!</p>\n\n<p>In addition, your <code>sudo pip3 list</code> clearly shows you are using tensorflow-gpu. If you would have the tensoflow cpu version the name would be something like <code>tensorflow(1.1.0)</code>.</p>\n\n<p>Check <a href=\"https://github.com/tensorflow/tensorflow/issues/7778\" rel=\"noreferrer\">this</a> issue for information about the warnings.</p>\n"}, {"title": "Get class labels from Keras functional model", "question_body": "<p>I have a functional model in Keras (Resnet50 from repo examples). I trained it with <code>ImageDataGenerator</code> and <code>flow_from_directory</code> data and saved model to <code>.h5</code> file. When I call <code>model.predict</code> I get an array of class probabilities. But I want to associate them with class labels (in my case - folder names). How can I get them? I found that I could use <code>model.predict_classes</code> and <code>model.predict_proba</code>, but I don't have these functions in Functional model, only in Sequential.</p>\n", "link": "https://stackoverflow.com/questions/38971293/get-class-labels-from-keras-functional-model", "question_id": 38971293, "accepted_answer_id": null}]