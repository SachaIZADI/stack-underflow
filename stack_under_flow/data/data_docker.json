[{"title": "How is Docker different from a virtual machine?", "question_body": "<p>I keep rereading <a href=\"https://docs.docker.com/\" rel=\"noreferrer\">the Docker documentation</a> to try to understand the difference between Docker and a full VM. How does it manage to provide a full filesystem, isolated networking environment, etc. without being as heavy?</p>\n\n<p>Why is deploying software to a Docker image (if that's the right term) easier than simply deploying to a consistent production environment?</p>\n", "link": "https://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-virtual-machine", "question_id": 16047306, "accepted_answer_id": 16048358, "answer_body": "<p>Docker originally used <a href=\"https://linuxcontainers.org/lxc/\" rel=\"noreferrer\">LinuX Containers</a> (LXC), but later switched to <a href=\"https://github.com/opencontainers/runc\" rel=\"noreferrer\">runC</a> (formerly known as <strong>libcontainer</strong>), which runs in the same operating system as its host. This allows it to share a lot of the host operating system resources. Also, it uses a layered filesystem (<a href=\"http://aufs.sourceforge.net/\" rel=\"noreferrer\">AuFS</a>) and manages networking.</p>\n\n<p>AuFS is a layered file system, so you can have a read only part and a write part which are merged together. One could have the common parts of the operating system as read only (and shared amongst all of your containers) and then give each container its own mount for writing.</p>\n\n<p>So, let's say you have a 1&nbsp;GB container image; if you wanted to use a full VM, you would need to have 1&nbsp;GB times x number of VMs you want. With Docker and AuFS you can share the bulk of the 1&nbsp;GB between all the containers and if you have 1000 containers you still might only have a little over 1&nbsp;GB of space for the containers OS (assuming they are all running the same OS image).</p>\n\n<p>A full virtualized system gets its own set of resources allocated to it, and does minimal sharing. You get more isolation, but it is much heavier (requires more resources). With Docker you get less isolation, but the containers are lightweight (require fewer resources). So you could easily run thousands of containers on a host, and it won't even blink. Try doing that with Xen, and unless you have a really big host, I don't think it is possible.</p>\n\n<p>A full virtualized system usually takes minutes to start, whereas Docker/LXC/runC containers take seconds, and often even less than a second.</p>\n\n<p>There are pros and cons for each type of virtualized system. If you want full isolation with guaranteed resources, a full VM is the way to go. If you just want to isolate processes from each other and want to run a ton of them on a reasonably sized host, then Docker/LXC/runC seems to be the way to go.</p>\n\n<p>For more information, check out <a href=\"http://web.archive.org/web/20150326185901/http://blog.dotcloud.com/under-the-hood-linux-kernels-on-dotcloud-part\" rel=\"noreferrer\">this set of blog posts</a> which do a good job of explaining how LXC works.</p>\n\n<blockquote>\n  <p>Why is deploying software to a docker image (if that's the right term) easier than simply deploying to a consistent production environment?</p>\n</blockquote>\n\n<p>Deploying a consistent production environment is easier said than done. Even if you use tools like <a href=\"https://en.wikipedia.org/wiki/Chef_%28software%29\" rel=\"noreferrer\">Chef</a> and <a href=\"https://en.wikipedia.org/wiki/Puppet_%28software%29\" rel=\"noreferrer\">Puppet</a>, there are always OS updates and other things that change between hosts and environments.</p>\n\n<p>Docker gives you the ability to snapshot the OS into a shared image, and makes it easy to deploy on other Docker hosts. Locally, dev, qa, prod, etc.: all the same image. Sure you can do this with other tools, but not nearly as easily or fast.</p>\n\n<p>This is great for testing; let's say you have thousands of tests that need to connect to a database, and each test needs a pristine copy of the database and will make changes to the data. The classic approach to this is to reset the database after every test either with custom code or with tools like <a href=\"https://flywaydb.org/\" rel=\"noreferrer\">Flyway</a> - this can be very time-consuming and means that tests must be run serially. However, with Docker you could create an image of your database and run up one instance per test, and then run all the tests in parallel since you know they will all be running against the same snapshot of the database. Since the tests are running in parallel and in Docker containers they could run all on the same box at the same time and should finish much faster. Try doing that with a full VM.</p>\n\n<p>From comments...</p>\n\n<blockquote>\n  <p>Interesting! I suppose I'm still confused by the notion of \"snapshot[ting] the OS\". How does one do that without, well, making an image of the OS?</p>\n</blockquote>\n\n<p>Well, let's see if I can explain. You start with a base image, and then make your changes, and commit those changes using docker, and it creates an image. This image contains only the differences from the base. When you want to run your image, you also need the base, and it layers your image on top of the base using a layered file system: as mentioned above, Docker uses AUFS. AUFS merges the different layers together and you get what you want; you just need to run it. You can keep adding more and more images (layers) and it will continue to only save the diffs. Since Docker typically builds on top of ready-made images from a <a href=\"https://registry.hub.docker.com/\" rel=\"noreferrer\">registry</a>, you rarely have to \"snapshot\" the whole OS yourself.</p>\n"}, {"title": "Should I use Vagrant or Docker for creating an isolated environment?", "question_body": "<p>I use Ubuntu for development and deployment and have a need for creating an isolated environment. </p>\n\n<p>I am considering either Vagrant or Docker for this purpose. What are the pros and cons, or how do these solutions compare?</p>\n", "link": "https://stackoverflow.com/questions/16647069/should-i-use-vagrant-or-docker-for-creating-an-isolated-environment", "question_id": 16647069, "accepted_answer_id": 16761439, "answer_body": "<p>If your purpose is the isolation, I think Docker is what you want.</p>\n\n<p>Vagrant is a virtual machine manager. It allows you to script the virtual machine configuration as well as the provisioning. However, it is still a virtual machine depending on <a href=\"http://en.wikipedia.org/wiki/VirtualBox\">VirtualBox</a> (or others) with a huge overhead. It requires you to have a hard drive file that can be huge, it takes a lot of ram, and performance may be not very good.</p>\n\n<p>Docker on the other hand uses kernel cgroup and namespacing via <a href=\"https://en.wikipedia.org/wiki/LXC\">LXC</a>. It means that you are using the same kernel as the host and the same file system.\nYou can use Dockerfile with the <code>docker build</code> command in order to handle the provisioning and configuration of your container. You have an example at <a href=\"https://docs.docker.com/\">docs.docker.com</a> on how to make your Dockerfile; it is very intuitive.</p>\n\n<p>The only reason you could want to use Vagrant is if you need to do BSD, Windows or other non-Linux development on your Ubuntu box. Otherwise, go for Docker.</p>\n"}, {"title": "What is the difference between the &#39;COPY&#39; and &#39;ADD&#39; commands in a Dockerfile?", "question_body": "<p>What is the difference between the <code>COPY</code> and <code>ADD</code> commands in a Dockerfile, and when would I use one over the other?</p>\n\n<pre><code>COPY &lt;src&gt; &lt;dest&gt;\n</code></pre>\n\n<blockquote>\n  <p>The COPY instruction will copy new files from <code>&lt;src&gt;</code> and add them to the container's filesystem at path <code>&lt;dest&gt;</code></p>\n</blockquote>\n\n<pre><code>ADD &lt;src&gt; &lt;dest&gt;\n</code></pre>\n\n<blockquote>\n  <p>The ADD instruction will copy new files from <code>&lt;src&gt;</code> and add them to the container's filesystem at path <code>&lt;dest&gt;</code>.</p>\n</blockquote>\n", "link": "https://stackoverflow.com/questions/24958140/what-is-the-difference-between-the-copy-and-add-commands-in-a-dockerfile", "question_id": 24958140, "accepted_answer_id": 24958548, "answer_body": "<p>You should check the <a href=\"https://docs.docker.com/engine/reference/builder/#add\" rel=\"noreferrer\"><code>ADD</code></a> and <a href=\"https://docs.docker.com/engine/reference/builder/#copy\" rel=\"noreferrer\"><code>COPY</code></a> documentation for an exhaustive description of their behaviours, but in a nutshell the major difference is that <code>ADD</code> can do more than <code>COPY</code>:</p>\n\n<ul>\n<li><code>ADD</code> allows <code>&lt;src&gt;</code> to be a URL</li>\n<li>Referring to comments bellow, the <code>ADD</code> <a href=\"https://docs.docker.com/engine/reference/builder/#add\" rel=\"noreferrer\">documentation</a> clearly states that:\n\n<blockquote>\n  <p>If  is a local tar archive in a recognized compression format (identity, gzip, bzip2 or xz) then it is unpacked as a directory. Resources from remote URLs are not decompressed.</p>\n</blockquote></li>\n</ul>\n\n<p>Note that the <a href=\"https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#add-or-copy\" rel=\"noreferrer\">Best practices for writing Dockerfiles</a> suggests using <code>COPY</code> where the magic of <code>ADD</code> is not required. Otherwise you (since you had to lookup this answer) are likely to get surprised someday when you mean to copy <code>keep_this_archive_intact.tar.gz</code> into your container, but instead you spray the contents onto your filesystem.</p>\n"}, {"title": "What is the difference between CMD and ENTRYPOINT in a Dockerfile?", "question_body": "<p>In Dockerfiles there are two commands that look similar to me: <code>CMD</code> and <code>ENTRYPOINT</code>. But I guess that there is a (subtle?) difference between them - otherwise it would not make any sense to have two commands for the very same thing.</p>\n\n<p>The documentation states for <code>CMD</code></p>\n\n<blockquote>\n  <p>The main purpose of a CMD is to provide defaults for an executing container.</p>\n</blockquote>\n\n<p>and for <code>ENTRYPOINT</code>:</p>\n\n<blockquote>\n  <p>An ENTRYPOINT helps you to configure a container that you can run as an executable.</p>\n</blockquote>\n\n<p>So, what's the difference between those two commands?</p>\n", "link": "https://stackoverflow.com/questions/21553353/what-is-the-difference-between-cmd-and-entrypoint-in-a-dockerfile", "question_id": 21553353, "accepted_answer_id": 21564990, "answer_body": "<p>Docker has a default entrypoint which is <code>/bin/sh -c</code> but does not have a default command.</p>\n\n<p>When you run docker like this:\n<code>docker run -i -t ubuntu bash</code>\nthe entrypoint is the default <code>/bin/sh -c</code>, the image is <code>ubuntu</code> and the command is <code>bash</code>.  </p>\n\n<p>The command is run via the entrypoint. i.e., the actual thing that gets executed is <code>/bin/sh -c bash</code>. This allowed Docker to implement <code>RUN</code> quickly by relying on the shell's parser.</p>\n\n<p>Later on, people asked to be able to customize this, so <code>ENTRYPOINT</code> and <code>--entrypoint</code> were introduced.</p>\n\n<p>Everything after <code>ubuntu</code> in the example above is the command and is passed to the entrypoint. When using the <code>CMD</code> instruction, it is exactly as if you were doing <code>docker run -i -t ubuntu &lt;cmd&gt;</code>. <code>&lt;cmd&gt;</code> will be the parameter of the entrypoint.</p>\n\n<p>You will also get the same result if you instead type this command <code>docker run -i -t ubuntu</code>. You will still start a bash shell in the container because of the <a href=\"https://github.com/dockerfile/ubuntu/blob/master/Dockerfile\" rel=\"noreferrer\">ubuntu Dockerfile</a> specified a default CMD: <code>CMD [\"bash\"]</code></p>\n\n<p>As everything is passed to the entrypoint, you can have a very nice behavior from your images. @Jiri example is good, it shows how to use an image as a \"binary\". When using <code>[\"/bin/cat\"]</code> as entrypoint and then doing <code>docker run img /etc/passwd</code>, you get it, <code>/etc/passwd</code> is the command and is passed to the entrypoint so the end result execution is simply <code>/bin/cat /etc/passwd</code>.</p>\n\n<p>Another example would be to have any cli as entrypoint. For instance, if you have a redis image, instead of running <code>docker run redisimg redis -H something -u toto get key</code>, you can simply have <code>ENTRYPOINT [\"redis\", \"-H\", \"something\", \"-u\", \"toto\"]</code> and then run like this for the same result: <code>docker run redisimg get key</code>.</p>\n"}, {"title": "Copying files from Docker container to host", "question_body": "<p>I'm thinking of using Docker to build my dependencies on a Continuous Integration (CI) server, so that I don't have to install all the runtimes and libraries on the agents themselves. </p>\n\n<p>To achieve this I would need to copy the build artifacts that are built inside the container back into the host. Is that possible?</p>\n", "link": "https://stackoverflow.com/questions/22049212/copying-files-from-docker-container-to-host", "question_id": 22049212, "accepted_answer_id": 22050116, "answer_body": "<p>In order to copy a file from a container to the host, you can use the command</p>\n\n<pre><code>docker cp &lt;containerId&gt;:/file/path/within/container /host/path/target\n</code></pre>\n\n<p>Here's an example:</p>\n\n<pre><code>$ sudo docker cp goofy_roentgen:/out_read.jpg .\n</code></pre>\n\n<p>Here goofy_roentgen is the name I got from the following command:</p>\n\n<pre><code>$ sudo docker ps\n\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                                            NAMES\n1b4ad9311e93        bamos/openface      \"/bin/bash\"         33 minutes ago      Up 33 minutes       0.0.0.0:8000-&gt;8000/tcp, 0.0.0.0:9000-&gt;9000/tcp   goofy_roentgen\n</code></pre>\n"}, {"title": "Copying files from host to Docker container", "question_body": "<p>I am trying to build a backup and restore solution for the Docker containers that we work with.</p>\n\n<p>I have Docker base image that I have created, <code>ubuntu:base</code>, and do not want have to rebuild it each time with a Docker file to add files to it.</p>\n\n<p>I want to create a script that runs from the host machine and creates a new container using the <code>ubuntu:base</code> Docker image and then copies files into that container.</p>\n\n<p>How can I copy files from the host to the container?</p>\n", "link": "https://stackoverflow.com/questions/22907231/copying-files-from-host-to-docker-container", "question_id": 22907231, "accepted_answer_id": 31971697, "answer_body": "<p>The <code>cp</code> command can be used to copy files. </p>\n\n<p>One specific file can be copied TO the container like:</p>\n\n<pre><code>docker cp foo.txt mycontainer:/foo.txt\n</code></pre>\n\n<p>One specific file can be copied FROM the container like:</p>\n\n<pre><code>docker cp mycontainer:/foo.txt foo.txt\n</code></pre>\n\n<p>For emphasis, <code>mycontainer</code> is a <em>container</em> ID, <strong>not</strong> an <em>image</em> ID.</p>\n\n<p>Multiple files contained by the folder <code>src</code> can be copied into the <code>target</code> folder using:</p>\n\n<pre><code>docker cp src/. mycontainer:/target\ndocker cp mycontainer:/src/. target\n</code></pre>\n\n<p>Reference: <a href=\"https://docs.docker.com/engine/reference/commandline/cp/\" rel=\"noreferrer\">Docker CLI docs for <code>cp</code></a> </p>\n\n<p>In Docker versions prior to 1.8 it was only possible to copy files from a container to the host. Not from the host to a container.</p>\n"}, {"title": "How to get a Docker container&#39;s IP address from the host?", "question_body": "<p>Is there a command I can run to get the container's IP address right from the host after a new container is created?</p>\n\n<p>Basically, once Docker creates the container, I want to roll my own code deployment and container configuration scripts.</p>\n", "link": "https://stackoverflow.com/questions/17157721/how-to-get-a-docker-containers-ip-address-from-the-host", "question_id": 17157721, "accepted_answer_id": 20686101, "answer_body": "<p>The <code>--format</code> option of inspect comes to the rescue.</p>\n\n<p>Modern Docker client syntax:</p>\n\n<pre><code>docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' container_name_or_id\n</code></pre>\n\n<p>Old Docker client syntax:</p>\n\n<pre><code>docker inspect --format '{{ .NetworkSettings.IPAddress }}' container_name_or_id\n</code></pre>\n\n<p>Which will return just the IP address.</p>\n\n<p>As mentioned in the comments: if you are on <strong>Windows</strong>, use double quotes <code>\"</code> instead of single quotes <code>'</code> around the curly braces. </p>\n"}, {"title": "How to remove old Docker containers", "question_body": "<p>This question is related to <em><a href=\"https://stackoverflow.com/questions/17014263/should-i-be-concerned-about-excess-non-running-docker-containers\">Should I be concerned about excess, non-running, Docker containers?</a></em>.</p>\n\n<p>I'm wondering how to remove old containers. The <code>docker rm 3e552code34a</code> lets you remove a single one, but I have lots already. <code>docker rm --help</code> doesn't give a selection option (like all, or by image name).</p>\n\n<p>Maybe there is a directory in which these containers are stored where I can delete them easily manually?</p>\n", "link": "https://stackoverflow.com/questions/17236796/how-to-remove-old-docker-containers", "question_id": 17236796, "accepted_answer_id": 17237701, "answer_body": "<p>Since <a href=\"https://github.com/moby/moby/blob/master/CHANGELOG.md#1130-2017-01-18\" rel=\"noreferrer\">Docker 1.13.x</a> you can use <a href=\"https://docs.docker.com/engine/reference/commandline/container_prune/\" rel=\"noreferrer\">Docker container prune</a>:</p>\n\n<pre><code>docker container prune\n</code></pre>\n\n<p>This will remove all stopped containers and should work on all platforms the same way.</p>\n\n<p>There is also a <a href=\"https://docs.docker.com/engine/reference/commandline/system_prune/\" rel=\"noreferrer\">Docker system prune</a>:</p>\n\n<pre><code>docker system prune\n</code></pre>\n\n<p>which will clean up all unused containers, networks, images (both dangling and unreferenced), and optionally, volumes, in one command.</p>\n\n<hr>\n\n<p>For older Docker versions, you can string Docker commands together with other Unix commands to get what you need. Here is an example on how to clean up old containers that are weeks old:</p>\n\n<pre><code>$ docker ps --filter \"status=exited\" | grep 'weeks ago' | awk '{print $1}' | xargs --no-run-if-empty docker rm\n</code></pre>\n\n<p>To give credit, where it is due, this example is from <a href=\"https://twitter.com/jpetazzo/status/347431091415703552\" rel=\"noreferrer\">https://twitter.com/jpetazzo/status/347431091415703552</a>.</p>\n"}, {"title": "How to copy Docker images from one host to another without using a repository", "question_body": "<p>How do I transfer a Docker image from one machine to another one without using a repository, no matter private or public?</p>\n\n<p>I am used to play and create my own image in VirtualBox, and when it is finished, I try to deploy to other machines to have real usage.</p>\n\n<p>Since it is based on own based image (like Red Hat Linux), it cannot be recreated from a Dockerfile.</p>\n\n<p>Are there simple commands I can use? Or another solution?</p>\n\n<p>It seems save/export can achieve a similar purpose, see <em><a href=\"https://stackoverflow.com/questions/22655867/what-is-the-difference-between-save-and-export-in-docker\">What is the difference between save and export in Docker?</a></em>, and I prefer the <code>save</code> command for my case.</p>\n", "link": "https://stackoverflow.com/questions/23935141/how-to-copy-docker-images-from-one-host-to-another-without-using-a-repository", "question_id": 23935141, "accepted_answer_id": 23938978, "answer_body": "<p>You will need to save the Docker image as a tar file:</p>\n\n<pre><code>docker save -o &lt;path for generated tar file&gt; &lt;image name&gt;\n</code></pre>\n\n<p>Then copy your image to a new system with regular file transfer tools such as <code>cp</code>, <code>scp</code> or <code>rsync</code>(preferred for big files). After that you will have to load the image into Docker:</p>\n\n<pre><code>docker load -i &lt;path to image tar file&gt;\n</code></pre>\n\n<p>PS: You may need to <code>sudo</code> all commands.</p>\n\n<p>EDIT: \nYou should add filename (not just directory) with -o, for example:</p>\n\n<pre><code>docker save -o c:/myfile.tar centos:16\n</code></pre>\n"}, {"title": "From inside of a Docker container, how do I connect to the localhost of the machine?", "question_body": "<p>So I have a Nginx running inside a docker container, I have a mysql running on localhost, I want to connect to the MySql from within my Nginx. The MySql is running on localhost and not exposing a port to the outside world, so its bound on localhost, not bound on the ip address of the machine.</p>\n\n<p>Is there any way to connect to this MySql or any other program on localhost from within this docker container?</p>\n", "link": "https://stackoverflow.com/questions/24319662/from-inside-of-a-docker-container-how-do-i-connect-to-the-localhost-of-the-mach", "question_id": 24319662, "accepted_answer_id": 24326540, "answer_body": "<p><strong>Edit:</strong> If you are using <a href=\"https://docs.docker.com/docker-for-mac/networking/#there-is-no-docker0-bridge-on-macos#i-want-to-connect-from-a-container-to-a-service-on-the-host\" rel=\"noreferrer\">Docker-for-mac</a> or <a href=\"https://docs.docker.com/docker-for-windows/networking/#there-is-no-docker0-bridge-on-windows#i-want-to-connect-from-a-container-to-a-service-on-the-host\" rel=\"noreferrer\">Docker-for-Windows</a> 18.03+, just connect to your mysql service using the host <code>host.docker.internal</code>. </p>\n\n<p><strong>As of Docker 18.09.3, this does not work on Docker-for-Linux.</strong> A <a href=\"https://github.com/docker/libnetwork/pull/2348\" rel=\"noreferrer\">fix</a> has been submitted on March the 8th, 2019 and will hopefully be merged to the code base. Until then, a workaround is to use a container as described in <a href=\"https://stackoverflow.com/a/52858101/107049\">qoomon's answer</a>.</p>\n\n<hr>\n\n<h2>TLDR</h2>\n\n<p>Use <code>--network=\"host\"</code> in your <code>docker run</code> command, then <code>127.0.0.1</code> in your docker container will point to your docker host.</p>\n\n<p>Note: This mode only works on Docker for Linux, <a href=\"https://docs.docker.com/network/host/\" rel=\"noreferrer\">per the documentation</a>.</p>\n\n<hr>\n\n<h1>Note on docker container networking modes</h1>\n\n<p>Docker offers <a href=\"https://docs.docker.com/engine/reference/run/#network-settings\" rel=\"noreferrer\">different networking modes</a> when running containers. Depending on the mode you choose you would connect to your MySQL database running on the docker host differently.</p>\n\n<h2>docker run --network=\"bridge\" (default)</h2>\n\n<p>Docker creates a bridge named <code>docker0</code> by default. Both the docker host and the docker containers have an IP address on that bridge.</p>\n\n<p>on the Docker host, type <code>sudo ip addr show docker0</code> you will have an output looking like:</p>\n\n<pre><code>[vagrant@docker:~] $ sudo ip addr show docker0\n4: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default\n    link/ether 56:84:7a:fe:97:99 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.42.1/16 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::5484:7aff:fefe:9799/64 scope link\n       valid_lft forever preferred_lft forever\n</code></pre>\n\n<p>So here my docker host has the IP address <code>172.17.42.1</code> on the <code>docker0</code> network interface.</p>\n\n<p>Now start a new container and get a shell on it: <code>docker run --rm -it ubuntu:trusty bash</code> and within the container type <code>ip addr show eth0</code> to discover how its main network interface is set up:</p>\n\n<pre><code>root@e77f6a1b3740:/# ip addr show eth0\n863: eth0: &lt;BROADCAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 66:32:13:f0:f1:e3 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.1.192/16 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::6432:13ff:fef0:f1e3/64 scope link\n       valid_lft forever preferred_lft forever\n</code></pre>\n\n<p>Here my container has the IP address <code>172.17.1.192</code>. Now look at the routing table:</p>\n\n<pre><code>root@e77f6a1b3740:/# route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\ndefault         172.17.42.1     0.0.0.0         UG    0      0        0 eth0\n172.17.0.0      *               255.255.0.0     U     0      0        0 eth0\n</code></pre>\n\n<p>So the IP Address of the docker host <code>172.17.42.1</code> is set as the default route and is accessible from your container.</p>\n\n<pre><code>root@e77f6a1b3740:/# ping 172.17.42.1\nPING 172.17.42.1 (172.17.42.1) 56(84) bytes of data.\n64 bytes from 172.17.42.1: icmp_seq=1 ttl=64 time=0.070 ms\n64 bytes from 172.17.42.1: icmp_seq=2 ttl=64 time=0.201 ms\n64 bytes from 172.17.42.1: icmp_seq=3 ttl=64 time=0.116 ms\n</code></pre>\n\n<h2>docker run --network=\"host\"</h2>\n\n<p>Alternatively you can run a docker container with <a href=\"http://docs.docker.com/engine/reference/run/#network-host\" rel=\"noreferrer\">network settings set to <code>host</code></a>. Such a container will share the network stack with the docker host and from the container point of view, <code>localhost</code> (or <code>127.0.0.1</code>) will refer to the docker host.</p>\n\n<p>Be aware that any port opened in your docker container would be opened on the docker host. And this without requiring the <a href=\"https://docs.docker.com/engine/reference/run/#expose-incoming-ports\" rel=\"noreferrer\"><code>-p</code> or <code>-P</code> <code>docker run</code> option</a>.</p>\n\n<p>IP config on my docker host:</p>\n\n<pre><code>[vagrant@docker:~] $ ip addr show eth0\n2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 08:00:27:98:dc:aa brd ff:ff:ff:ff:ff:ff\n    inet 10.0.2.15/24 brd 10.0.2.255 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::a00:27ff:fe98:dcaa/64 scope link\n       valid_lft forever preferred_lft forever\n</code></pre>\n\n<p>and from a docker container in <strong>host</strong> mode:</p>\n\n<pre><code>[vagrant@docker:~] $ docker run --rm -it --network=host ubuntu:trusty ip addr show eth0\n2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 08:00:27:98:dc:aa brd ff:ff:ff:ff:ff:ff\n    inet 10.0.2.15/24 brd 10.0.2.255 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::a00:27ff:fe98:dcaa/64 scope link\n       valid_lft forever preferred_lft forever\n</code></pre>\n\n<p>As you can see both the docker host and docker container share the exact same network interface and as such have the same IP address.</p>\n\n<hr>\n\n<h1>Connecting to MySQL from containers</h1>\n\n<h2>bridge mode</h2>\n\n<p>To access MySQL running on the docker host from containers in <em>bridge mode</em>, you need to make sure the MySQL service is listening for connections on the <code>172.17.42.1</code> IP address.</p>\n\n<p>To do so, make sure you have either <code>bind-address = 172.17.42.1</code> or <code>bind-address = 0.0.0.0</code> in your MySQL config file (my.cnf). </p>\n\n<p>If you need to set an environment variable with the IP address of the gateway, you can run the following code in a container :</p>\n\n<pre><code>export DOCKER_HOST_IP=$(route -n | awk '/UG[ \\t]/{print $2}')\n</code></pre>\n\n<p>then in your application, use the <code>DOCKER_HOST_IP</code> environment variable to open the connection to MySQL.</p>\n\n<p><strong>Note:</strong> if you use <code>bind-address = 0.0.0.0</code> your MySQL server will listen for connections on all network interfaces. That means your MySQL server could be reached from the Internet ; make sure to setup firewall rules accordingly.</p>\n\n<p><strong>Note 2:</strong> if you use <code>bind-address = 172.17.42.1</code> your MySQL server won't listen for connections made to <code>127.0.0.1</code>. Processes running on the docker host that would want to connect to MySQL would have to use the <code>172.17.42.1</code> IP address.</p>\n\n<h2>host mode</h2>\n\n<p>To access MySQL running on the docker host from containers in <em>host mode</em>, you can keep <code>bind-address = 127.0.0.1</code> in your MySQL configuration and all you need to do is to connect to <code>127.0.0.1</code> from your containers:</p>\n\n<pre><code>[vagrant@docker:~] $ docker run --rm -it --network=host mysql mysql -h 127.0.0.1 -uroot -p\nEnter password:\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 36\nServer version: 5.5.41-0ubuntu0.14.04.1 (Ubuntu)\n\nCopyright (c) 2000, 2014, Oracle and/or its affiliates. All rights reserved.\n\nOracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nmysql&gt;\n</code></pre>\n\n<p><strong>note:</strong> Do use <code>mysql -h 127.0.0.1</code> and not <code>mysql -h localhost</code>; otherwise the MySQL client would try to connect using a unix socket.</p>\n"}, {"title": "How to deal with persistent storage (e.g. databases) in Docker", "question_body": "<p>How do people deal with persistent storage for your Docker containers?</p>\n\n<p>I am currently using this approach: build the image, e.g. for PostgreSQL, and then start the container with</p>\n\n<pre><code>docker run --volumes-from c0dbc34fd631 -d app_name/postgres\n</code></pre>\n\n<p>IMHO, that has the drawback, that I must not ever (by accident) delete container \"c0dbc34fd631\".</p>\n\n<p>Another idea would be to mount host volumes \"-v\" into the container, however, the <strong>userid</strong> within the container does not necessarily match the <strong>userid</strong> from the host, and then permissions might be messed up.</p>\n\n<p>Note: Instead of <code>--volumes-from 'cryptic_id'</code> you can also use <code>--volumes-from my-data-container</code> where <code>my-data-container</code> is a name you assigned to a data-only container, e.g. <code>docker run --name my-data-container ...</code> (see the accepted answer)</p>\n", "link": "https://stackoverflow.com/questions/18496940/how-to-deal-with-persistent-storage-e-g-databases-in-docker", "question_id": 18496940, "accepted_answer_id": 20652410, "answer_body": "<h2>Docker 1.9.0 and above</h2>\n\n<p>Use <a href=\"https://docs.docker.com/engine/reference/commandline/volume_create/\" rel=\"noreferrer\">volume API</a></p>\n\n<pre><code>docker volume create --name hello\ndocker run -d -v hello:/container/path/for/volume container_image my_command\n</code></pre>\n\n<p>This means that the data-only container pattern must be abandoned in favour of the new volumes.</p>\n\n<p>Actually the volume API is only a better way to achieve what was the data-container pattern.</p>\n\n<p>If you create a container with a <code>-v volume_name:/container/fs/path</code> Docker will automatically create a named volume for you that can:</p>\n\n<ol>\n<li>Be listed through the <code>docker volume ls</code></li>\n<li>Be identified through the <code>docker volume inspect volume_name</code></li>\n<li>Backed up as a normal directory</li>\n<li>Backed up as before through a <code>--volumes-from</code> connection</li>\n</ol>\n\n<p>The new volume API adds a useful command that lets you identify dangling volumes:</p>\n\n<pre><code>docker volume ls -f dangling=true\n</code></pre>\n\n<p>And then remove it through its name:</p>\n\n<pre><code>docker volume rm &lt;volume name&gt;\n</code></pre>\n\n<p>As @mpugach underlines in the comments, you can get rid of all the dangling volumes with a nice one-liner:</p>\n\n<pre><code>docker volume rm $(docker volume ls -f dangling=true -q)\n# Or using 1.13.x\ndocker volume prune\n</code></pre>\n\n<h2>Docker 1.8.x and below</h2>\n\n<p>The approach that seems to work best for production is to use a <strong>data only container</strong>.</p>\n\n<p>The data only container is run on a barebones image and actually does nothing except exposing a data volume.</p>\n\n<p>Then you can run any other container to have access to the data container volumes:</p>\n\n<pre><code>docker run --volumes-from data-container some-other-container command-to-execute\n</code></pre>\n\n<ul>\n<li><a href=\"http://www.offermann.us/2013/12/tiny-docker-pieces-loosely-joined.html\" rel=\"noreferrer\">Here</a> you can get a good picture of how to arrange the different containers.</li>\n<li><a href=\"http://crosbymichael.com/advanced-docker-volumes.html\" rel=\"noreferrer\">Here</a> there is a good insight on how volumes work.</li>\n</ul>\n\n<p>In <a href=\"http://container42.com/2013/12/16/persistent-volumes-with-docker-container-as-volume-pattern/\" rel=\"noreferrer\">this blog post</a> there is a good description of the so-called <strong>container as volume pattern</strong> which clarifies the main point of having <strong>data only containers</strong>.</p>\n\n<p><a href=\"https://docs.docker.com/engine/userguide/dockervolumes/\" rel=\"noreferrer\">Docker documentation has now the DEFINITIVE description of the <strong>container as volume/s</strong> pattern.</a></p>\n\n<p>Following is the backup/restore procedure for Docker 1.8.x and below.</p>\n\n<p><strong>BACKUP:</strong></p>\n\n<pre><code>sudo docker run --rm --volumes-from DATA -v $(pwd):/backup busybox tar cvf /backup/backup.tar /data\n</code></pre>\n\n<ul>\n<li>--rm: remove the container when it exits</li>\n<li>--volumes-from DATA: attach to the volumes shared by the DATA container</li>\n<li>-v $(pwd):/backup: bind mount the current directory into the container; to write the tar file to</li>\n<li>busybox: a small simpler image - good for quick maintenance</li>\n<li>tar cvf /backup/backup.tar /data: creates an uncompressed tar file of all the files in the /data directory</li>\n</ul>\n\n<p><strong>RESTORE:</strong></p>\n\n<pre><code># Create a new data container\n$ sudo docker run -v /data -name DATA2 busybox true\n# untar the backup files into the new container\u1fbfs data volume\n$ sudo docker run --rm --volumes-from DATA2 -v $(pwd):/backup busybox tar xvf /backup/backup.tar\ndata/\ndata/sven.txt\n# Compare to the original container\n$ sudo docker run --rm --volumes-from DATA -v `pwd`:/backup busybox ls /data\nsven.txt\n</code></pre>\n\n<p>Here is a nice <a href=\"http://container42.com/2014/11/18/data-only-container-madness/\" rel=\"noreferrer\">article from the excellent Brian Goff</a> explaining why it is good to use the same image for a container and a data container.</p>\n"}, {"title": "How do I get into a Docker container&#39;s shell?", "question_body": "<p>I'm getting started working with Docker. I'm using the WordPress base image and docker-compose.</p>\n\n<p>I'm trying to ssh into one of the containers to inspect the files/directories that were created during the initial build. I tried to run <code>docker-compose run containername ls -la</code>, but that didn't do anything. Even if it did, I'd rather have a console where I can traverse the directory structure, rather than run a single command. What is the right way to do this with Docker?</p>\n", "link": "https://stackoverflow.com/questions/30172605/how-do-i-get-into-a-docker-containers-shell", "question_id": 30172605, "accepted_answer_id": 30173220, "answer_body": "<p><code>docker attach</code> will let you connect to your Docker container, but this isn't really the same thing as <code>ssh</code>.  If your container is running a webserver, for example, <code>docker attach</code> will probably connect you to the <em>stdout</em> of the web server process.  It won't necessarily give you a shell.</p>\n\n<p>The <code>docker exec</code> command is probably what you are looking for; this will let you run arbitrary commands inside an existing container.  For example:</p>\n\n<pre><code>docker exec -it &lt;mycontainer&gt; bash\n</code></pre>\n\n<p>Of course, whatever command you are running must exist in the container filesystem.</p>\n\n<p>In the above command <code>&lt;mycontainer&gt;</code> is the name or ID of the target container.  It doesn't matter whether or not you're using <code>docker compose</code>; just run <code>docker ps</code> and use either the ID (a hexadecimal string displayed in the first column) or the name (displayed in the final column).  E.g., given:</p>\n\n<pre><code>$ docker ps\nd2d4a89aaee9        larsks/mini-httpd   \"mini_httpd -d /cont   7 days ago          Up 7 days                               web                 \n</code></pre>\n\n<p>I can run:</p>\n\n<pre><code>$ docker exec -it web ip addr\n1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN \n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n18: eth0: &lt;BROADCAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP \n    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.3/16 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:acff:fe11:3/64 scope link \n       valid_lft forever preferred_lft forever\n</code></pre>\n\n<p>I could accomplish the same thing by running:</p>\n\n<pre><code>$ docker exec -it d2d4a89aaee9 ip addr\n</code></pre>\n\n<p>Similarly, I could start a shell in the container;</p>\n\n<pre><code>$ docker exec -it web sh\n/ # echo This is inside the container.\nThis is inside the container.\n/ # exit\n$\n</code></pre>\n"}, {"title": "How to list containers in Docker", "question_body": "<p>There's a command to list images, <code>docker images</code>, but there doesn't seem to be a corresponding <code>docker containers</code>.</p>\n\n<p>Other than becoming root and looking into <code>/var/lib/docker</code> there doesn't seem a way to do that. Am I missing something? Is that something one isn't supposed to do?</p>\n", "link": "https://stackoverflow.com/questions/16840409/how-to-list-containers-in-docker", "question_id": 16840409, "accepted_answer_id": 16842203, "answer_body": "<p>To show only <strong>running containers</strong> use the given command:</p>\n\n<pre><code>docker ps\n</code></pre>\n\n<p>To show <strong>all containers</strong> use the given command:</p>\n\n<pre><code>docker ps -a\n</code></pre>\n\n<p>To show the <strong>latest created container</strong> (includes all states) use the given command:</p>\n\n<pre><code>docker ps -l\n</code></pre>\n\n<p>To show <strong>n last created containers</strong> (includes all states) use the given command:</p>\n\n<pre><code>docker ps -n=-1\n</code></pre>\n\n<p>To display <strong>total file sizes</strong> use the given command:</p>\n\n<pre><code>docker ps -s\n</code></pre>\n\n<p>The content presented above is from <a href=\"https://docs.docker.com/v1.11/engine/reference/commandline/ps/\" rel=\"noreferrer\">docker.com</a>.</p>\n\n<p>In the new version of Docker, commands are updated, and some management commands are added:</p>\n\n<pre><code>docker container ls\n</code></pre>\n\n<p>Is used to list all the running containers.</p>\n\n<pre><code>docker container ls -a\n</code></pre>\n\n<p>And then, if you want to clean them all,</p>\n\n<pre><code>docker rm $(docker ps -aq)\n</code></pre>\n\n<p>Is used to list all the containers created irrespective of its state.</p>\n\n<p>Here container is the management command.</p>\n"}, {"title": "How does one remove an image in Docker?", "question_body": "<p>I'm running Docker under Vagrant under OS X 10.8.4  (Mountain Lion), and whenever I try to delete a saved image, I get an error:</p>\n\n<pre><code>$ docker rmi some-image-id\n2013/07/15 hh:mm:ss unexpected JSON input\n</code></pre>\n\n<p>According to the <code>rmi</code> help, the proper syntax is <code>docker rmi IMAGE [IMAGE...]</code>, and I'm not sure what to make of that.</p>\n\n<p>How can I delete an image?</p>\n\n<pre><code>$ docker version\nClient version: 0.4.8\nServer version: 0.4.8\nGo version: go1.1\n</code></pre>\n\n<p>\u00a0</p>\n\n<pre><code>$docker info\nContainers: 1\nImages: 3\n</code></pre>\n\n<p>Interestingly, when I run <code>docker ps</code>, no containers show up at all. Running <code>docker images</code> shows four (4) <code>base</code> images and one (1) <code>node</code> image.</p>\n", "link": "https://stackoverflow.com/questions/17665283/how-does-one-remove-an-image-in-docker", "question_id": 17665283, "accepted_answer_id": 17870293, "answer_body": "<p>Try <code>docker rmi node</code>. That should work. </p>\n\n<p>Seeing all created containers is as simple as <code>docker ps -a</code>. </p>\n\n<p>To remove all existing containers (not images!) run <code>docker rm $(docker ps -aq)</code></p>\n"}, {"title": "Where are Docker images stored on the host machine?", "question_body": "<p>I managed to find the containers under directory <code>/var/lib/docker/containers</code>, but I can't find the images.</p>\n\n<p>What are the directories and files under <code>/var/lib/docker</code>?</p>\n", "link": "https://stackoverflow.com/questions/19234831/where-are-docker-images-stored-on-the-host-machine", "question_id": 19234831, "accepted_answer_id": 25978888, "answer_body": "<p>The contents of the <code>/var/lib/docker</code> directory vary depending on the <a href=\"https://github.com/docker/docker/blob/990a3e30fa66e7bd3df3c78c873c97c5b1310486/daemon/graphdriver/driver.go#L37-L43\" rel=\"noreferrer\">driver Docker is using for storage</a>. </p>\n\n<p>By default this will be <code>aufs</code> but can fall back to <code>overlay</code>, <code>overlay2</code>, <code>btrfs</code>, <code>devicemapper</code> or <code>zfs</code> depending on your kernel support. In most places this will be <code>aufs</code> but the <a href=\"http://developerblog.redhat.com/2014/09/30/overview-storage-scalability-docker/\" rel=\"noreferrer\">RedHats went with <code>devicemapper</code></a>.</p>\n\n<p>You can manually set the storage driver with the <a href=\"https://docs.docker.com/engine/reference/commandline/dockerd/#/daemon-storage-driver-option\" rel=\"noreferrer\"><code>-s</code> or <code>--storage-driver=</code></a> option to the <a href=\"https://docs.docker.com/engine/reference/commandline/dockerd/\" rel=\"noreferrer\">Docker daemon</a>. </p>\n\n<ul>\n<li><code>/var/lib/docker/{driver-name}</code> will contain the driver specific storage for contents of the images. </li>\n<li><code>/var/lib/docker/graph/&lt;id&gt;</code> now only contains metadata about the image, in the <code>json</code> and <code>layersize</code> files.</li>\n</ul>\n\n<p>In the case of <code>aufs</code>:</p>\n\n<ul>\n<li><code>/var/lib/docker/aufs/diff/&lt;id&gt;</code> has the file contents of the images.</li>\n<li><code>/var/lib/docker/repositories-aufs</code> is a JSON file containing local image information. This can be viewed with the command <code>docker images</code>.</li>\n</ul>\n\n<p>In the case of <code>devicemapper</code>:</p>\n\n<ul>\n<li><code>/var/lib/docker/devicemapper/devicemapper/data</code> stores the images</li>\n<li><code>/var/lib/docker/devicemapper/devicemapper/metadata</code> the metadata</li>\n<li>Note these files are thin provisioned \"sparse\" files so aren't as big as they seem.</li>\n</ul>\n"}, {"title": "What is the difference between a Docker image and a container?", "question_body": "<p>When using Docker, we start with a base image. We boot it up, create changes and those changes are saved in layers forming another image.</p>\n\n<p>So eventually I have an image for my PostgreSQL instance and an image for my web application, changes to which keep on being persisted.</p>\n\n<p>So the question is: What is a container?</p>\n", "link": "https://stackoverflow.com/questions/23735149/what-is-the-difference-between-a-docker-image-and-a-container", "question_id": 23735149, "accepted_answer_id": 23736802, "answer_body": "<p>An instance of an image is called a container. You have an image, which is a set of layers as you describe. If you start this image, you have a running container of this image. You can have many running containers of the same image.</p>\n\n<p>You can see all your images with <code>docker images</code> whereas you can see your running containers with <code>docker ps</code> (and you can see all containers with <code>docker ps -a</code>).</p>\n\n<p>So a running instance of an image is a container.</p>\n"}, {"title": "How do I pass environment variables to Docker containers?", "question_body": "<p>I'm new to Docker, and it's unclear how to access an external database from a container. Is the best way to hard-code in the connection string?</p>\n\n<pre><code># Dockerfile\nENV DATABASE_URL amazon:rds/connection?string\n</code></pre>\n", "link": "https://stackoverflow.com/questions/30494050/how-do-i-pass-environment-variables-to-docker-containers", "question_id": 30494050, "accepted_answer_id": 30494145, "answer_body": "<p>You can pass environment variables to your containers with the <code>-e</code> flag.</p>\n\n<p>An example from a startup script:</p>\n\n<pre><code>sudo docker run -d -t -i -e REDIS_NAMESPACE='staging' \\ \n-e POSTGRES_ENV_POSTGRES_PASSWORD='foo' \\\n-e POSTGRES_ENV_POSTGRES_USER='bar' \\\n-e POSTGRES_ENV_DB_NAME='mysite_staging' \\\n-e POSTGRES_PORT_5432_TCP_ADDR='docker-db-1.hidden.us-east-1.rds.amazonaws.com' \\\n-e SITE_URL='staging.mysite.com' \\\n-p 80:80 \\\n--link redis:redis \\  \n--name container_name dockerhub_id/image_name\n</code></pre>\n\n<p>Or, if you don't want to have the value on the command-line where it will be displayed by <code>ps</code>, etc., <code>-e</code> can pull in the value from the current environment if you just give it without the <code>=</code>:</p>\n\n<pre><code>sudo PASSWORD='foo' docker run  [...] -e PASSWORD [...]\n</code></pre>\n\n<p>If you have many environment variables and especially if they're meant to be secret, you can <a href=\"https://docs.docker.com/engine/reference/commandline/run/#set-environment-variables--e---env---env-file\">use an env-file</a>:</p>\n\n<pre><code>$ docker run --env-file ./env.list ubuntu bash\n</code></pre>\n\n<blockquote>\n  <p>The --env-file flag takes a filename as an argument and expects each line to be in the VAR=VAL format, mimicking the argument passed to --env. Comment lines need only be prefixed with #</p>\n</blockquote>\n"}, {"title": "How to remove old and unused Docker images", "question_body": "<p>When running Docker for a long time, there are a lot of images in system. How can I remove all unused Docker images at once safety to free up the storage?</p>\n\n<p>In addition, I also want to remove images pulled months ago, which have the correct <code>TAG</code>.</p>\n\n<p>So, I'm not asking for removing untagged images only. I'm searching for a way to remove general unused images, which includes both untagged and other images such as pulled months ago with correct <code>TAG</code>.</p>\n", "link": "https://stackoverflow.com/questions/32723111/how-to-remove-old-and-unused-docker-images", "question_id": 32723111, "accepted_answer_id": 32723127, "answer_body": "<p>Update Sept. 2016: Docker 1.13: <a href=\"https://github.com/docker/docker/pull/26108\" rel=\"noreferrer\">PR 26108</a> and <a href=\"https://github.com/docker/docker/commit/86de7c000f5d854051369754ad1769194e8dd5e1\" rel=\"noreferrer\">commit 86de7c0</a> introduce a few new commands to help facilitate visualizing how much space the docker daemon data is taking on disk and allowing for easily cleaning up \"unneeded\" excess.</p>\n\n<p><a href=\"https://docs.docker.com/engine/reference/commandline/system_prune/\" rel=\"noreferrer\"><strong><code>docker system prune</code></strong></a> will delete ALL dangling data (i.e. In order: containers stopped, volumes without containers and images with no containers). Even unused data, with <code>-a</code> option.</p>\n\n<p>You also have:</p>\n\n<ul>\n<li><a href=\"https://docs.docker.com/engine/reference/commandline/container_prune/\" rel=\"noreferrer\"><code>docker container prune</code></a></li>\n<li><a href=\"https://docs.docker.com/engine/reference/commandline/image_prune/\" rel=\"noreferrer\"><code>docker image prune</code></a></li>\n<li><a href=\"https://docs.docker.com/engine/reference/commandline/network_prune/\" rel=\"noreferrer\"><code>docker network prune</code></a></li>\n<li><a href=\"https://docs.docker.com/engine/reference/commandline/volume_prune/\" rel=\"noreferrer\"><code>docker volume prune</code></a></li>\n</ul>\n\n<p>For <em>unused</em> images, use <code>docker image prune -a</code> (for removing dangling <em>and</em> ununsed images).<br>\nWarning: '<em>unused</em>' means \"images not referenced by any container\": be careful before using <code>-a</code>.</p>\n\n<p>As illustrated in <a href=\"https://stackoverflow.com/users/1207596/a-l\">A L</a>'s <a href=\"https://stackoverflow.com/a/50405599/6309\">answer</a>, <code>docker system prune --all</code> will remove all <em>unused</em> images not just dangling ones... which can be a bit too much.</p>\n\n<p>Combining <code>docker xxx prune</code> with the <a href=\"https://docs.docker.com/engine/reference/commandline/system_prune/#filtering\" rel=\"noreferrer\"><code>--filter</code> option</a> can be a great way to limit the pruning (<a href=\"https://docs.docker.com/develop/sdk/#api-version-matrix\" rel=\"noreferrer\">docker SDK API 1.28 minimum, so docker 17.04+</a>)</p>\n\n<blockquote>\n  <p>The currently supported filters are:</p>\n</blockquote>\n\n<ul>\n<li><code>until (&lt;timestamp&gt;)</code> - only remove containers, images, and networks created before given timestamp</li>\n<li><code>label</code> (<code>label=&lt;key&gt;</code>, <code>label=&lt;key&gt;=&lt;value&gt;</code>, <code>label!=&lt;key&gt;</code>, or <code>label!=&lt;key&gt;=&lt;value&gt;</code>) - only remove containers, images, networks, and volumes with (or <em>without</em>, in case <code>label!=...</code> is used) the specified labels.</li>\n</ul>\n\n<p>See \"<a href=\"https://docs.docker.com/config/pruning/#prune-images\" rel=\"noreferrer\">Prune images</a>\" for an example.</p>\n\n<hr>\n\n<p>Original answer (Sep. 2016)</p>\n\n<p>I usually do:</p>\n\n<pre><code>docker rmi $(docker images --filter \"dangling=true\" -q --no-trunc)\n</code></pre>\n\n<p>I have an <a href=\"https://github.com/docker/docker/blob/634a848b8e3bdd8aed834559f3b2e0dfc7f5ae3a/man/docker-images.1.md#options\" rel=\"noreferrer\">alias for removing those [dangling images]<a href=\"https://github.com/docker/docker/blob/634a848b8e3bdd8aed834559f3b2e0dfc7f5ae3a/man/docker-images.1.md#options\" rel=\"noreferrer\">13</a>: <code>drmi</code></a></p>\n\n<blockquote>\n  <p>The <code>dangling=true</code> filter finds unused images</p>\n</blockquote>\n\n<p>That way, any intermediate image no longer referenced by a labelled image is removed.</p>\n\n<p>I do the same <strong>first</strong> for <a href=\"https://github.com/VonC/b2d/blob/b010ab51974ac7de6162cdcbff795d7b9e84fd67/.bash_aliases#L21\" rel=\"noreferrer\">exited processes (containers)</a></p>\n\n<pre><code>alias drmae='docker rm $(docker ps -qa --no-trunc --filter \"status=exited\")'\n</code></pre>\n\n<p>As <a href=\"https://stackoverflow.com/users/95750/haridsv\">haridsv</a> points out <a href=\"https://stackoverflow.com/questions/32723111/how-to-remove-old-and-unused-docker-images/32723127#comment63457575_32723127\">in the comments</a>:</p>\n\n<blockquote>\n  <p>Technically, <strong>you should first clean up containers before cleaning up images, as this will catch more dangling images and less errors</strong>.</p>\n</blockquote>\n\n<hr>\n\n<p><a href=\"https://github.com/jfrazelle\" rel=\"noreferrer\">Jess Frazelle (jfrazelle)</a> has the <a href=\"https://github.com/jfrazelle/dotfiles/blob/a7fd3df6ab423e6dd04f27727f653753453db837/.dockerfunc#L8-L11\" rel=\"noreferrer\">bashrc function</a>:</p>\n\n<pre><code>dcleanup(){\n    docker rm -v $(docker ps --filter status=exited -q 2&gt;/dev/null) 2&gt;/dev/null\n    docker rmi $(docker images --filter dangling=true -q 2&gt;/dev/null) 2&gt;/dev/null\n}\n</code></pre>\n\n<hr>\n\n<p>To remove old images, and not just \"unreferenced-dangling\" images, you can consider <a href=\"https://github.com/spotify/docker-gc\" rel=\"noreferrer\"><strong><code>docker-gc</code></strong></a>:</p>\n\n<hr>\n\n<blockquote>\n  <p>A simple Docker container and image garbage collection script.</p>\n  \n  <ul>\n  <li>Containers that exited more than an hour ago are removed.</li>\n  <li>Images that don't belong to any remaining container after that are removed.</li>\n  </ul>\n</blockquote>\n"}, {"title": "How to force Docker for a clean build of an image", "question_body": "<p>I have build a Docker image from a Docker file using the below command.</p>\n\n<pre><code>$ docker build -t u12_core -f u12_core .\n</code></pre>\n\n<p>When I am trying to rebuild it with the same command, it's using the build cache like:</p>\n\n<pre><code>Step 1 : FROM ubuntu:12.04\n ---&gt; eb965dfb09d2\nStep 2 : MAINTAINER Pavan Gupta &lt;pavan.gupta@gmail.com&gt;\n ---&gt; Using cache\n ---&gt; 4354ccf9dcd8\nStep 3 : RUN apt-get update\n ---&gt; Using cache\n ---&gt; bcbca2fcf204\nStep 4 : RUN apt-get install -y openjdk-7-jdk\n ---&gt; Using cache\n ---&gt; 103f1a261d44\nStep 5 : RUN apt-get install -y openssh-server\n ---&gt; Using cache\n ---&gt; dde41f8d0904\nStep 6 : RUN apt-get install -y git-core\n ---&gt; Using cache\n ---&gt; 9be002f08b6a\nStep 7 : RUN apt-get install -y build-essential\n ---&gt; Using cache\n ---&gt; a752fd73a698\nStep 8 : RUN apt-get install -y logrotate\n ---&gt; Using cache\n ---&gt; 93bca09b509d\nStep 9 : RUN apt-get install -y lsb-release\n ---&gt; Using cache\n ---&gt; fd4d10cf18bc\nStep 10 : RUN mkdir /var/run/sshd\n ---&gt; Using cache\n ---&gt; 63b4ecc39ff0\nStep 11 : RUN echo 'root:root' | chpasswd\n ---&gt; Using cache\n ---&gt; 9532e31518a6\nStep 12 : RUN sed -i 's/PermitRootLogin without-password/PermitRootLogin yes/' /etc/ssh/sshd_config\n ---&gt; Using cache\n ---&gt; 47d1660bd544\nStep 13 : RUN sed 's@session\\s*required\\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd\n ---&gt; Using cache\n ---&gt; d1f97f1c52f7\nStep 14 : RUN wget -O aerospike.tgz 'http://aerospike.com/download/server/latest/artifact/ubuntu12'\n ---&gt; Using cache\n ---&gt; bd7dde7a98b9\nStep 15 : RUN tar -xvf aerospike.tgz\n ---&gt; Using cache\n ---&gt; 54adaa09921f\nStep 16 : RUN dpkg -i aerospike-server-community-*/*.deb\n ---&gt; Using cache\n ---&gt; 11aba013eea5\nStep 17 : EXPOSE 22 3000 3001 3002 3003\n ---&gt; Using cache\n ---&gt; e33aaa78a931\nStep 18 : CMD /usr/sbin/sshd -D\n ---&gt; Using cache\n ---&gt; 25f5fe70fa84\nSuccessfully built 25f5fe70fa84\n</code></pre>\n\n<p>The cache shows that aerospike is installed. However, I don't find it inside containers spawn from this image, so I want to rebuild this image without using the cache. How can I force Docker to rebuild a clean image without the cache?</p>\n", "link": "https://stackoverflow.com/questions/35594987/how-to-force-docker-for-a-clean-build-of-an-image", "question_id": 35594987, "accepted_answer_id": 35595021, "answer_body": "<p>There's a <code>--no-cache</code> option:</p>\n\n<pre><code>docker build --no-cache -t u12_core -f u12_core .\n</code></pre>\n\n<p>In older versions of Docker you needed to pass <code>--no-cache=true</code>, but this is no longer the case.</p>\n"}, {"title": "Exploring Docker container&#39;s file system", "question_body": "<p>I've noticed with docker that I need to understand what's happening inside a container or what files exist in there. One example is downloading images from the docker index - you don't have a clue what the image contains so it's impossible to start the application.</p>\n\n<p>What would be ideal is to be able to ssh into them or equivalent. Is there a tool to do this, or is my conceptualisation of docker wrong in thinking I should be able to do this.</p>\n", "link": "https://stackoverflow.com/questions/20813486/exploring-docker-containers-file-system", "question_id": 20813486, "accepted_answer_id": 20816397, "answer_body": "<p><strong>Method 1: snapshoting</strong></p>\n\n<p>You can evaluate container filesystem this way:</p>\n\n<pre><code># find ID of your running container:\ndocker ps\n\n# create image (snapshot) from container filesystem\ndocker commit 12345678904b5 mysnapshot\n\n# explore this filesystem using bash (for example)\ndocker run -t -i mysnapshot /bin/bash\n</code></pre>\n\n<p>This way, you can evaluate filesystem of the running container in the precise time moment. Container is still running, no future changes are included.</p>\n\n<p>You can later delete snapshot using (filesystem of the running container is not affected!):</p>\n\n<pre><code>docker rmi mysnapshot\n</code></pre>\n\n<p><strong>Method 2: ssh</strong></p>\n\n<p>If you need continuous access, you can install sshd to your container and run the sshd daemon:</p>\n\n<pre><code> docker run -d -p 22 mysnapshot /usr/sbin/sshd -D\n\n # you need to find out which port to connect:\n docker ps\n</code></pre>\n\n<p>This way, you can run your app using ssh (connect and execute what you want).</p>\n\n<p><strong>UPDATE - Method 3: nsenter</strong></p>\n\n<p>Use <code>nsenter</code>, see <a href=\"http://blog.docker.com/2014/06/why-you-dont-need-to-run-sshd-in-docker/\">http://blog.docker.com/2014/06/why-you-dont-need-to-run-sshd-in-docker/</a></p>\n\n<blockquote>\n  <p><em>The short version is: with nsenter, you can get a shell into an\n  existing container, even if that container doesn\u2019t run SSH or any kind\n  of special-purpose daemon</em></p>\n</blockquote>\n\n<p><strong>UPDATE - Method 4: docker exec</strong></p>\n\n<p>Docker version 1.3 (latest, you might need to use docker apt repo to install latest version as of Nov 2014) supports new command <code>exec</code> that behave similar to <code>nsenter</code>. This command can run new process in already running container (container must have PID 1 process running already). You can run <code>/bin/bash</code> to explore container state:</p>\n\n<pre><code>docker exec -t -i mycontainer /bin/bash\n</code></pre>\n\n<p>see <a href=\"https://docs.docker.com/v1.3/reference/commandline/cli/#exec\">Docker command line documentation</a></p>\n"}, {"title": "How to mount a host directory in a Docker container", "question_body": "<p>I am trying to mount a host directory into a Docker container so that any updates done on the host is reflected into the Docker containers.</p>\n\n<p>Where am I doing something wrong. Here is what I did:</p>\n\n<pre><code>kishore$ cat Dockerfile\n\nFROM ubuntu:trusty\nRUN apt-get update\nRUN apt-get -y install git curl vim\nCMD [\"/bin/bash\"]\nWORKDIR /test_container\nVOLUME [\"/test_container\"]\n</code></pre>\n\n<p><pre><code>kishore$ tree\n.\n\u251c\u2500\u2500 Dockerfile\n\u2514\u2500\u2500 main_folder\n    \u251c\u2500\u2500 tfile1.txt\n    \u251c\u2500\u2500 tfile2.txt\n    \u251c\u2500\u2500 tfile3.txt\n    \u2514\u2500\u2500 tfile4.txt</p>\n\n<p>1 directory, 5 files\nkishore$ pwd\n/Users/kishore/tdock\n</code></pre><pre><code>kishore$ docker build --tag=k3_s3:latest .</p>\n\n<pre><code>Uploading context 7.168 kB\nUploading context\nStep 0 : FROM ubuntu:trusty\n ---&gt; 99ec81b80c55\nStep 1 : RUN apt-get update\n ---&gt; Using cache\n ---&gt; 1c7282005040\nStep 2 : RUN apt-get -y install git curl vim\n ---&gt; Using cache\n ---&gt; aed48634e300\nStep 3 : CMD [\"/bin/bash\"]\n ---&gt; Running in d081b576878d\n ---&gt; 65db8df48595\nStep 4 : WORKDIR /test_container\n ---&gt; Running in 5b8d2ccd719d\n ---&gt; 250369b30e1f\nStep 5 : VOLUME [\"/test_container\"]\n ---&gt; Running in 72ca332d9809\n ---&gt; 163deb2b1bc5\nSuccessfully built 163deb2b1bc5\nRemoving intermediate container b8bfcb071441\nRemoving intermediate container d081b576878d\nRemoving intermediate container 5b8d2ccd719d\nRemoving intermediate container 72ca332d9809\n</code></pre>\n\n<p>kishore$ docker run -d -v /Users/kishore/main_folder:/test_container k3_s3:latest\n<code>c9f9a7e09c54ee1c2cc966f15c963b4af320b5203b8c46689033c1ab8872a0ea</code></code></pre><pre><code>kishore$ docker run -i -t k3_s3:latest /bin/bash</p>\n\n<pre><code>root@0f17e2313a46:/test_container# ls -al\ntotal 8\ndrwx------  2 root root 4096 Apr 29 05:15 .\ndrwxr-xr-x 66 root root 4096 Apr 29 05:15 ..\n</code></pre>\n\n<p>root@0f17e2313a46:/test_container# exit\nexit</code></pre><pre><code>kishore$ docker -v\nDocker version 0.9.1, build 867b2a9</code></pre></p>\n\n<ul>\n<li>I don't know how to check boot2docker version</li>\n</ul>\n\n<p>Questions, issues facing:</p>\n\n<ol>\n<li>How do I need to link the main_folder to the test_container folder present inside the docker container?</li>\n<li>I need to make this automatically. How do I to do that without really using the <code>run -d -v</code> command?</li>\n<li>What happens if the boot2docker crashes? Where are the Docker files stored (apart from Dockerfile)?</li>\n</ol>\n", "link": "https://stackoverflow.com/questions/23439126/how-to-mount-a-host-directory-in-a-docker-container", "question_id": 23439126, "accepted_answer_id": null}, {"title": "Run a Docker Image as a Container", "question_body": "<p>I built a docker image from a dockerfile. I see the image was built successfully, but what do I do with it? Shouldn't it be able to run as a container?</p>\n\n<p>New to docker so probably a misunderstanding on my end, any help would be great. </p>\n", "link": "https://stackoverflow.com/questions/18497688/run-a-docker-image-as-a-container", "question_id": 18497688, "accepted_answer_id": 18498313, "answer_body": "<p>The specific way to run it depends on whether you gave the image a tag/name or not.</p>\n\n<pre><code>$ docker images\nREPOSITORY          TAG                 ID                  CREATED             SIZE\nubuntu              12.04               8dbd9e392a96        4 months ago        131.5 MB (virtual 131.5 MB)\n</code></pre>\n\n<p>With a name (let's use <em>Ubuntu</em>):</p>\n\n<pre><code>$ docker run -i -t ubuntu:12.04 /bin/bash\n</code></pre>\n\n<p>Without a name, just using the ID:</p>\n\n<pre><code>$ docker run -i -t 8dbd9e392a96 /bin/bash\n</code></pre>\n\n<p>Please see <a href=\"https://docs.docker.com/engine/reference/run/\" rel=\"noreferrer\">https://docs.docker.com/engine/reference/run/</a> for more information.</p>\n"}, {"title": "Docker how to change repository name or rename image?", "question_body": "<p>I'm trying to change repository name of the image:</p>\n\n<pre><code>REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\nserver              latest              d583c3ac45fd        26 minutes ago      685.5 MB\n</code></pre>\n\n<p>Hence I want to change the name <code>server</code> to something like <code>myname/server</code>:</p>\n\n<pre><code>REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\nmyname/server       latest              d583c3ac45fd        26 minutes ago      685.5 MB\n</code></pre>\n\n<p>How can I do this?</p>\n", "link": "https://stackoverflow.com/questions/25211198/docker-how-to-change-repository-name-or-rename-image", "question_id": 25211198, "accepted_answer_id": 25214186, "answer_body": "<pre><code>docker tag server:latest myname/server:latest\n</code></pre>\n\n<p>or</p>\n\n<pre><code>docker tag d583c3ac45fd myname/server:latest\n</code></pre>\n\n<p>Tags are just human-readable aliases for the full image name (<code>d583c3ac45fd...</code>). </p>\n\n<p>So you can have as many of them associated with the same image as you like. If you don't like the old name you can remove it after you've retagged it:</p>\n\n<pre><code>docker rmi server\n</code></pre>\n\n<p>That will just remove the <code>alias/tag</code>. Since <code>d583c3ac45fd</code> has other names, the actual image won't be deleted.</p>\n"}, {"title": "How to enter in a Docker container already running with a new TTY", "question_body": "<p>I have a container that is running the Apache service in the foreground. I would like to be able to access the container from another shell in order to \"poke around\" inside it and examine the files. At the moment, if I attach to the container, I am left looking at the Apache daemon and cannot run any commands.</p>\n\n<p>Is it possible to attach another tty to a running container? Possibly, I can take advantage of the fact that Docker is actually just wrapping around LXC containers? I have tried <code>sudo lxc-console -n [container-id] -t [1-4]</code> but it appears that only one tty is made available and that is the one running the apache daemon. Perhaps there is a way to enable multiple lxc consoles during the build?</p>\n\n<p>I would rather <strong>not</strong> configure and build the container with an openssh service if possible.</p>\n", "link": "https://stackoverflow.com/questions/20932357/how-to-enter-in-a-docker-container-already-running-with-a-new-tty", "question_id": 20932357, "accepted_answer_id": 26496854, "answer_body": "<p>With docker 1.3, there is a new command <a href=\"https://docs.docker.com/engine/reference/commandline/exec/\" rel=\"noreferrer\"><code>docker exec</code></a>. This allows you to enter a running docker:</p>\n\n<pre><code>docker exec -it [container-id] bash\n</code></pre>\n"}, {"title": "How to upgrade docker container after its image changed", "question_body": "<p>Let's say I have pulled the official <a href=\"https://registry.hub.docker.com/_/mysql/\" rel=\"noreferrer\">mysql:5.6.21 image</a>. </p>\n\n<p>I have deployed this image by creating several docker containers.</p>\n\n<p>These containers have been running for some time until MySQL 5.6.22 is released. The official image of mysql:5.6 gets updated with the new release, but my containers still run 5.6.21.</p>\n\n<p>How do I propagate the changes in the image (i.e. upgrade MySQL distro) to all my existing containers? What is the proper Docker way of doing this?</p>\n", "link": "https://stackoverflow.com/questions/26734402/how-to-upgrade-docker-container-after-its-image-changed", "question_id": 26734402, "accepted_answer_id": null}, {"title": "What is the runtime performance cost of a Docker container?", "question_body": "<p>I'd like to comprehensively understand the run-time performance cost of a Docker container. I've found references to <a href=\"https://stackoverflow.com/questions/21691540/how-to-optimize-performance-for-a-docker-container/21707838#21707838\">networking anecdotally being ~100\u00b5s slower</a>.</p>\n\n<p>I've also found references to the run-time cost being \"negligible\" and \"close to zero\" but I'd like to know more precisely what those costs are. Ideally I'd like to know what Docker is abstracting with a performance cost and things that are abstracted without a performance cost. Networking, CPU, memory, etc.</p>\n\n<p>Furthermore, if there are abstraction costs, are there ways to get around the abstraction cost. For example, perhaps I can mount a disk directly vs. virtually in Docker.</p>\n", "link": "https://stackoverflow.com/questions/21889053/what-is-the-runtime-performance-cost-of-a-docker-container", "question_id": 21889053, "accepted_answer_id": 26149994, "answer_body": "<p><a href=\"http://domino.research.ibm.com/library/cyberdig.nsf/papers/0929052195DD819C85257D2300681E7B/$File/rc25482.pdf\" rel=\"noreferrer\">Here</a> is an excellent 2014 IBM research paper titled \"An Updated Performance Comparison of Virtual Machines and Linux Containers\" by Felter et al. that provides a comparison between bare metal, KVM, and Docker containers. <strong>The general result is that Docker is nearly identical to Native performance and faster than KVM in every category.</strong></p>\n\n<p>The exception to this is Docker's NAT - if you use port mapping (e.g. <code>docker run -p 8080:8080</code>) then you can expect a minor hit in latency, as shown below. However, you can now use the host network stack (e.g. <code>docker run --net=host</code>) when launching a Docker container, which will perform identically to the <code>Native</code> column (as shown in the Redis latency results lower down). </p>\n\n<p><img src=\"https://i.stack.imgur.com/4yRh1m.png\" alt=\"Docker NAT overhead\"></p>\n\n<p>They also ran latency tests on a few specific services, such as Redis. You can see that above 20 client threads, highest latency overhead goes Docker NAT, then KVM, then a rough tie between Docker host/native. </p>\n\n<p><img src=\"https://i.stack.imgur.com/9RH9lm.png\" alt=\"docker Redis latency overhead\"></p>\n\n<p>Just because it's a really useful paper, here are some other figures. Please download it for full access. </p>\n\n<p>Taking a look at Disk IO:</p>\n\n<p><img src=\"https://i.stack.imgur.com/2Ftytm.png\" alt=\"IO docker vs kvm vs native\"></p>\n\n<p>Now looking at CPU overhead: </p>\n\n<p><img src=\"https://i.stack.imgur.com/wZZH6m.png\" alt=\"docker cpu overhead\"></p>\n\n<p>Now some examples of memory (read the paper for details, memory can be extra tricky)</p>\n\n<p><img src=\"https://i.stack.imgur.com/aHPVkm.png\" alt=\"docker memory comparison\"></p>\n"}, {"title": "What is the difference between &quot;expose&quot; and &quot;publish&quot; in Docker?", "question_body": "<p>I'm experimenting with Dockerfiles, and I think I understand most of the logic. However, I don't see the difference between \"exposing\" and \"publishing\" a port in this context.</p>\n\n<p>All the tutorials I have seen first include the <code>EXPOSE</code> command in the Dockerfile:</p>\n\n<pre><code>...\nEXPOSE 8080\n...\n</code></pre>\n\n<p>They then build an image from this Dockerfile:</p>\n\n<pre><code>$ docker build -t an_image - &lt; Dockerfile\n</code></pre>\n\n<p>And then <em>publish</em> the same port as above when running the image:</p>\n\n<pre><code>$ docker run -d -p 8080 an_image\n</code></pre>\n\n<p>or publish all ports using</p>\n\n<pre><code>$ docker run -d -P an_image\n</code></pre>\n\n<p>What is the point of exposing a port in the Dockerfile, if it will be published anyway? Would there ever be a need to expose a port first, and <em>not</em> publish it later? Effectively, I would like to specify all the ports that I will use in the Dockerfile when creating the image, and then not bother with them again, running them simply with:</p>\n\n<pre><code>$ docker run -d an_image\n</code></pre>\n\n<p>Is this possible?</p>\n", "link": "https://stackoverflow.com/questions/22111060/what-is-the-difference-between-expose-and-publish-in-docker", "question_id": 22111060, "accepted_answer_id": 22150099, "answer_body": "<p>Basically, you have three options:</p>\n\n<ol>\n<li>Neither specify <code>EXPOSE</code> nor <code>-p</code></li>\n<li>Only specify <code>EXPOSE</code></li>\n<li>Specify <code>EXPOSE</code> and <code>-p</code></li>\n</ol>\n\n<p>1) If you specify neither <code>EXPOSE</code> nor <code>-p</code>, the service in the container will only be accessible from <em>inside</em> the container itself.</p>\n\n<p>2) If you <code>EXPOSE</code> a port, the service in the container is not accessible from outside Docker, but from inside other Docker containers. So this is good for inter-container communication.</p>\n\n<p>3) If you <code>EXPOSE</code> and <code>-p</code> a port, the service in the container is accessible from anywhere, even outside Docker.</p>\n\n<p>The reason why both are separated is IMHO because:</p>\n\n<ul>\n<li>choosing a host port depends on the host and hence does not belong to the Dockerfile (otherwise it would be depending on the host),</li>\n<li>and often it's enough if a service in a container is accessible from other containers.</li>\n</ul>\n\n<p>The <a href=\"https://docs.docker.com/engine/reference/builder/#expose\" rel=\"noreferrer\">documentation</a> explicitly states:</p>\n\n<blockquote>\n  <p>The <code>EXPOSE</code> instruction exposes ports for use within links.</p>\n</blockquote>\n\n<p>It also points you to how to <a href=\"https://docs.docker.com/userguide/dockerlinks/\" rel=\"noreferrer\">link containers</a>, which basically is the inter-container communication I talked about.</p>\n\n<p>PS: If you do <code>-p</code>, but do not <code>EXPOSE</code>, Docker does an implicit <code>EXPOSE</code>. This is because if a port is open to the public, it is automatically also open to other Docker containers. Hence <code>-p</code> includes <code>EXPOSE</code>. That's why I didn't list it above as a fourth case.</p>\n"}, {"title": "How do I edit a file after I shell to a Docker container?", "question_body": "<p>I successfully shelled to a Docker container using</p>\n\n<pre><code>docker exec -i -t 69f1711a205e bash\n</code></pre>\n\n<p>Now I need to edit file and I don't have any editors inside:</p>\n\n<pre><code>root@69f1711a205e:/# nano\nbash: nano: command not found\nroot@69f1711a205e:/# pico\nbash: pico: command not found\nroot@69f1711a205e:/# vi\nbash: vi: command not found\nroot@69f1711a205e:/# vim\nbash: vim: command not found\nroot@69f1711a205e:/# emacs\nbash: emacs: command not found\nroot@69f1711a205e:/#\n</code></pre>\n\n<p>How do I edit files?</p>\n", "link": "https://stackoverflow.com/questions/30853247/how-do-i-edit-a-file-after-i-shell-to-a-docker-container", "question_id": 30853247, "accepted_answer_id": 30859601, "answer_body": "<p>As in the comments, there's no default editor set - strange - the <code>$EDITOR</code> environment variable is empty. You can log in into a container with:</p>\n\n<pre><code>docker exec -it &lt;container&gt; bash\n</code></pre>\n\n<p>And run:</p>\n\n<pre><code>apt-get update\napt-get install vim\n</code></pre>\n\n<p>Or use the following Dockerfile:</p>\n\n<pre><code>FROM  confluent/postgres-bw:0.1\n\nRUN [\"apt-get\", \"update\"]\nRUN [\"apt-get\", \"install\", \"-y\", \"vim\"]\n</code></pre>\n\n<p>Docker images are delivered trimmed to the bare minimum - so no editor is installed with the shipped container. That's why there's a need to install it manually.</p>\n\n<p><strong>EDIT</strong></p>\n\n<p>I also encourage you read my <a href=\"https://blog.softwaremill.com/editing-files-in-a-docker-container-f36d76b9613c\" rel=\"noreferrer\">post</a> about the topic.</p>\n"}, {"title": "How do I run a command on an already existing Docker container?", "question_body": "<p>I created a container with <code>-d</code> so it's not interactive.</p>\n\n<pre><code>docker run -d shykes/pybuilder bin/bash\n</code></pre>\n\n<p>I see that the container has exited:</p>\n\n<pre><code>CONTAINER ID        IMAGE                     COMMAND             CREATED             STATUS                      PORTS               NAMES\nd6c45e8cc5f0        shykes/pybuilder:latest   \"bin/bash\"          41 minutes ago      Exited (0) 2 seconds ago                        clever_bardeen\n</code></pre>\n\n<p>Now I would like to run occasional commands on the machine and exit. Just to get the response.</p>\n\n<p>I tried to start the machine. I tried attaching. I thought I could call <code>run</code> with a container, but that does not seem to be allowed. Using <code>start</code> just seems to run and then exist quickly.</p>\n\n<p>I'd like to get back into interactive mode after exiting.</p>\n\n<p>I tried:</p>\n\n<pre><code>docker attach d6c45e8cc5f0\n</code></pre>\n\n<p>But I get:</p>\n\n<pre><code>2014/10/01 22:33:34 You cannot attach to a stopped container, start it first\n</code></pre>\n\n<p>But if I start it, it exits anyway. Catch 22. I can't win.</p>\n", "link": "https://stackoverflow.com/questions/26153686/how-do-i-run-a-command-on-an-already-existing-docker-container", "question_id": 26153686, "accepted_answer_id": 27708039, "answer_body": "<p>In October 2014 the <a href=\"http://blog.docker.com/2014/10/docker-1-3-signed-images-process-injection-security-options-mac-shared-directories/\" rel=\"noreferrer\">Docker team introduced <code>docker exec</code> command</a>: <a href=\"https://docs.docker.com/engine/reference/commandline/exec/\" rel=\"noreferrer\">https://docs.docker.com/engine/reference/commandline/exec/</a></p>\n\n<p>So now you can run any command in a running container just knowing its ID (or name):</p>\n\n<pre><code>docker exec -it &lt;container_id_or_name&gt; echo \"Hello from container!\"\n</code></pre>\n\n<p>Note that <code>exec</code> command works only on already running container. If the container is currently stopped, you need to first run it with the following command:</p>\n\n<pre><code>docker run -it -d shykes/pybuilder /bin/bash\n</code></pre>\n\n<p>The most important thing here is the <code>-d</code> option, which stands for <code>detached</code>. It means that the command you initially provided to the container (<code>/bin/bash</code>) will be run in the background and the container will not <em>stop immediately</em>.</p>\n"}, {"title": "Docker can&#39;t connect to docker daemon", "question_body": "<p>After I update my Docker version to <code>0.8.0</code>, I get an error message while entering <code>sudo docker version</code>:</p>\n\n<pre><code>Client version: 0.8.0\nGo version (client): go1.2\nGit commit (client): cc3a8c8\n2014/02/19 12:54:16 Can't connect to docker daemon. Is 'docker -d' running on this host?\n</code></pre>\n\n<p>And I've followed the instructions and entered command <code>sudo docker -d</code>, and I got this:</p>\n\n<pre><code>[/var/lib/docker|2462000b] +job initserver()\n[/var/lib/docker|2462000b.initserver()] Creating server\nopen /var/lib/docker/aufs/layers/cf2414da53f9bcfaa48bc3d58360d7f1cfd3784e4fe51fbef95197709dfc285d: no such file or directory[/var/lib/docker|2462000b] -job initserver() = ERR (1)\n2014/02/19 12:55:57 initserver: open /var/lib/docker/aufs/layers/cf2414da53f9bcfaa48bc3d58360d7f1cfd3784e4fe51fbef95197709dfc285d: no such file or directory\n</code></pre>\n\n<p>How do I solve the problem?</p>\n", "link": "https://stackoverflow.com/questions/21871479/docker-cant-connect-to-docker-daemon", "question_id": 21871479, "accepted_answer_id": null}]